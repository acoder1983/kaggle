{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(plyr)\n",
    "paths = list(data='../raw_data/',\n",
    "             submit='../raw_data/',\n",
    "             r='../R/')\n",
    "\n",
    "sample.submission <- function(){\n",
    "  # Loads the sample submission, which is used in writing predictions\n",
    "  ss <- read.csv(paste0(paths$data, 'sampleSubmission.csv'))\n",
    "}\n",
    "\n",
    "raw.train <- function(){\n",
    "  # Loads the training data with correct classes\n",
    "  cls <- c('factor', 'factor', 'Date', 'numeric', 'logical')\n",
    "  train <- read.csv(paste0(paths$data, 'train.csv'), \n",
    "                    colClasses=cls)\n",
    "}\n",
    "\n",
    "raw.test <- function(){\n",
    "  # Loads the test data with correct column types\n",
    "  cls <- c('factor', 'factor', 'Date', 'logical')\n",
    "  test <- read.csv(paste0(paths$data, 'test.csv'), \n",
    "                   colClasses=cls)\n",
    "}\n",
    "\n",
    "reload.submission <- function(submit.num){\n",
    "  # Reloads a previously saved submission\n",
    "  #\n",
    "  # args:\n",
    "  #  submit.num - the number of the submission\n",
    "  #\n",
    "  # returns:\n",
    "  #  the saved submission as a data frame (with Id $ Weekly_Sales fields)\n",
    "  submit.path <- paste0(paths$submit, 'submission', submit.num, '.csv')\n",
    "  read.csv(submit.path)\n",
    "}\n",
    "\n",
    "make.average <- function(submissions, wts=NULL){\n",
    "  # Averages previously saved submissions.\n",
    "  #\n",
    "  # args:\n",
    "  #  submissions - a vector of submission numbers\n",
    "  #  wts - optional vector of weights for submissions\n",
    "  #\n",
    "  # returns:\n",
    "  #  a data frame with the weighted average of the Weekly_Sales fields\n",
    "  #  from the submissions as its Weekly_Sales field\n",
    "  if(is.null(wts)){\n",
    "    wts <- rep(1, length(submissions))\n",
    "  }\n",
    "  pred <- sample.submission()\n",
    "  for(k in 1:length(submissions)){\n",
    "    sub.k <- reload.submission(submissions[k])\n",
    "    pred.k <- wts[k] * sub.k$Weekly_Sales\n",
    "    pred$Weekly_Sales <- pred$Weekly_Sales + pred.k\n",
    "  }\n",
    "  pred$Weekly_Sales <- pred$Weekly_Sales/sum(wts)\n",
    "  pred\n",
    "}\n",
    "\n",
    "write.submission <- function(pred){\n",
    "  # Writes a valid submission to paths$submit.\n",
    "  #\n",
    "  # args:\n",
    "  #  pred - a data frame with predictions in the Weekly_Sales field\n",
    "  #\n",
    "  # returns:\n",
    "  #  the submission number used\n",
    "  ss <- sample.submission()\n",
    "  subs <- dir(paths$submit)\n",
    "  subs <- grep('submission[0-9]+(.csv)(.zip|.gz)?', subs, value=TRUE)\n",
    "  nums <- gsub('submission','', gsub('(.csv)(.zip|.gz)?','', subs))\n",
    "  if(length(nums) == 0){\n",
    "    submission.number <- 1\n",
    "  }else{\n",
    "    submission.number <- max(as.numeric(nums)) + 1\n",
    "  }\n",
    "  ss$Weekly_Sales <- pred$Weekly_Sales\n",
    "  submit.path = paste0(paths$submit, \n",
    "                       'submission', \n",
    "                       submission.number,\n",
    "                       '.csv')\n",
    "  print(paste('Writing to:', submit.path))\n",
    "  write.csv(ss, file = submit.path, quote=FALSE, row.names=FALSE)\n",
    "  submission.number\n",
    "}\n",
    "\n",
    "wmae <- function(pred, test){\n",
    "  # Computes the evaluation metric for Kaggle/Walmart.\n",
    "  #\n",
    "  # args:\n",
    "  #  pred - a data frame with predictions in the Weekly_Sales field\n",
    "  #  test - a data frame with an IsHoliday field and with the ground truth\n",
    "  #         in the Weekly_Sales field\n",
    "  # returns:\n",
    "  #  wmae - the weighted mean absolute error\n",
    "  w <- 4*test$IsHoliday + 1\n",
    "  sum(w*abs(pred$Weekly_Sales - test$Weekly_Sales))/sum(w)\n",
    "}\n",
    "\n",
    "require(plyr)\n",
    "require(forecast)\n",
    "require(reshape)\n",
    "\n",
    "grouped.forecast <- function(train, test, fname, ...){\n",
    "  # Iterates over the departments and calls a model function to make forecasts\n",
    "  # on each of them.\n",
    "  #\n",
    "  # args:\n",
    "  #  train - a data frame containing the data from train.csv, or part of it.\n",
    "  #  test - a data frame like that returned by raw.test()\n",
    "  #  fname - a string specifying which model function to call\n",
    "  #\n",
    "  # returns:\n",
    "  #  a data frame corresponding to the test parameter, but with all of the \n",
    "  #  predictions in the Weekly_Sales field\n",
    "  FNAMES <- c('seasonal.naive',\n",
    "              'product',\n",
    "              'stlf.svd',\n",
    "              'fourier.arima',\n",
    "              'stlf.nn',\n",
    "              'seasonal.arima.svd',\n",
    "              'tslm.basic')\n",
    "  \n",
    "  if(fname %in% FNAMES){\n",
    "    f <- get(fname)\n",
    "  }else{\n",
    "    stop(fname,' not legal forecast option')\n",
    "  }\n",
    "  if('Weekly_Sales' %in% names(test)){\n",
    "    test <- subset(test, select=-Weekly_Sales)\n",
    "  }\n",
    "  \n",
    "  test.dates <- unique(test$Date)\n",
    "  num.test.dates <- length(test.dates)\n",
    "  all.stores <- unique(test$Store)\n",
    "  num.stores <- length(all.stores)\n",
    "  test.depts <- unique(test$Dept)\n",
    "  #reverse the depts so the grungiest data comes first\n",
    "  test.depts <- test.depts[length(test.depts):1]\n",
    "  forecast.frame <- data.frame(Date=rep(test.dates, num.stores),\n",
    "                           Store=rep(all.stores, each=num.test.dates))\n",
    "  pred <- test\n",
    "  pred$Weekly_Sales <- 0\n",
    "  \n",
    "  train.dates <- unique(train$Date)\n",
    "  num.train.dates <- length(train.dates)\n",
    "  train.frame <- data.frame(Date=rep(train.dates, num.stores),\n",
    "                            Store=rep(all.stores, each=num.train.dates))\n",
    "  \n",
    "  for(d in test.depts){\n",
    "    if(d==1){\n",
    "    print(paste('dept:', d))\n",
    "    tr.d <- train.frame\n",
    "    # This joins in Weekly_Sales but generates NA's. Resolve NA's \n",
    "    # in the model because they are resolved differently in different models.\n",
    "    tr.d <- join(tr.d, train[train$Dept==d, c('Store','Date','Weekly_Sales')])\n",
    "    tr.d <- cast(tr.d, Date ~ Store)    \n",
    "    fc.d <- forecast.frame\n",
    "    fc.d$Weekly_Sales <- 0\n",
    "    fc.d <- cast(fc.d, Date ~ Store)\n",
    "    result <- f(tr.d, fc.d, d, ...)\n",
    "    # This has all Stores/Dates for this dept, but may have some that\n",
    "    # don't go into the submission.\n",
    "    result <- melt(result)\n",
    "    pred.d.idx <- pred$Dept==d\n",
    "    #These are the Store-Date pairs in the submission for this dept\n",
    "    pred.d <- pred[pred.d.idx, c('Store', 'Date')]\n",
    "    pred.d <- join(pred.d, result)\n",
    "    pred$Weekly_Sales[pred.d.idx] <- pred.d$value\n",
    "        }\n",
    "  }\n",
    "  pred\n",
    "}\n",
    "\n",
    "seasonal.naive <- function(train, test){\n",
    "  # Computes seasonal naive forecasts\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  h <- nrow(test)\n",
    "  tr <- train[nrow(train) - (52:1) + 1,]\n",
    "  tr[is.na(tr)] <- 0\n",
    "  test[,2:ncol(test)]  <- tr[1:h,2:ncol(test)]\n",
    "  test\n",
    "}\n",
    "\n",
    "product <- function(train, test){\n",
    "  # Computes forecasts with the product model. This model predicts the mean\n",
    "  # value by store times the mean value by week divided by the mean value\n",
    "  # over the department.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  h <- nrow(test)\n",
    "  tr <- train[nrow(train) - (52:1) + 1,]\n",
    "  tr[is.na(tr)] <- 0\n",
    "  levels <- colMeans(tr[,2:ncol(tr)])\n",
    "  profile <- rowMeans(tr[,2:ncol(tr)])\n",
    "  overall <- mean(levels)\n",
    "  pred <- matrix(profile, ncol=1) %*% matrix(levels, nrow=1)\n",
    "  pred <- pred / overall\n",
    "  test[,2:ncol(test)] <- pred[1:h,]\n",
    "  test\n",
    "}\n",
    "\n",
    "tslm.basic <- function(train, test){\n",
    "  # Computes a forecast using linear regression and seasonal dummy variables\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  \n",
    "  horizon <- nrow(test)\n",
    "  train[is.na(train)] <- 0\n",
    "  for(j in 2:ncol(train)){\n",
    "    s <- ts(train[, j], frequency=52)\n",
    "    model <- tslm(s ~ trend + season)\n",
    "    fc <- forecast(model, h=horizon)\n",
    "    test[, j] <- as.numeric(fc$mean)\n",
    "  }\n",
    "  test\n",
    "}\n",
    "\n",
    "stlf.svd <- function(train, test, d, model.type, n.comp){\n",
    "  # Replaces the training data with a rank-reduced approximation of itself,\n",
    "  # then forecasts each store using stlf() from the forecast package.\n",
    "  # That function performs an STL decomposition on each series, seasonally\n",
    "  # adjusts the data, non-seasonally forecasts the seasonally adjusted data,\n",
    "  # and then adds in the naively extended seasonal component to get the\n",
    "  # final forecast.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  # model.type - one of 'ets' or 'arima', specifies which type of model to\n",
    "  #        use for the non-seasonal forecast\n",
    "  # n.comp - the number of components to keep in the singular value\n",
    "  #         decomposition that is performed for preprocessing\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  \n",
    "  horizon <- nrow(test)\n",
    "  train <- preprocess.svd(train, n.comp, d) \n",
    "  for(j in 2:ncol(train)){\n",
    "    s <- ts(train[, j], frequency=52)\n",
    "    if(model.type == 'ets'){\n",
    "      fc <- stlf(s, \n",
    "                 h=horizon, \n",
    "                 s.window=3, \n",
    "                 method='ets',\n",
    "                 ic='bic', \n",
    "                 opt.crit='mae')\n",
    "    }else if(model.type == 'arima'){\n",
    "      fc <- stlf(s, \n",
    "                 h=horizon, \n",
    "                 s.window=3, \n",
    "                 method='arima',\n",
    "                 ic='bic')\n",
    "    }else{\n",
    "      stop('Model type must be one of ets or arima.')\n",
    "    }\n",
    "    pred <- as.numeric(fc$mean)\n",
    "    test[, j] <- pred\n",
    "  }\n",
    "  test\n",
    "}\n",
    "\n",
    "stlf.nn <- function(train, test, method='ets', k, level1, level2){\n",
    "  # Function standard scales the series and computes a correlation matrix.\n",
    "  # Then it forecasts each store using stlf() from the forecast package.\n",
    "  # That function performs an STL decomposition on each series, seasonally\n",
    "  # adjusts the data, non-seasonally forecasts the seasonally adjusted data,\n",
    "  # and then adds in the naively extended seasonal component to get the\n",
    "  # final forecast.\n",
    "  # Finally, it averages together some of the most correlated series before\n",
    "  # restoring the original scale.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  # method - one of 'ets' or 'arima', specifies which type of model to\n",
    "  #        use for the non-seasonal forecast\n",
    "  # level1 - all series correlated to this level are used in the average\n",
    "  # level2 - no series are used if they are correlated to less than this level\n",
    "  # k - up to k series that are above level2 will be selected\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  horizon <- nrow(test)\n",
    "  tr <- train[, 2:ncol(train)]\n",
    "  tr[is.na(tr)] <- 0\n",
    "  crl <- cor(tr)\n",
    "  tr.scale <- scale(tr)\n",
    "  tr.scale[is.na(tr.scale)] <- 0\n",
    "  raw.pred <- test[, 2:ncol(test)]\n",
    "  for(j in 1:ncol(tr)){\n",
    "    s <- ts(tr.scale[, j], frequency=52)\n",
    "    if(method == 'ets'){\n",
    "      fc <- stlf(s, \n",
    "                 h=horizon, \n",
    "                 s.window=3, \n",
    "                 method='ets',\n",
    "                 ic='bic', \n",
    "                 opt.crit='mae')\n",
    "    }else if(method == 'arima'){\n",
    "      fc <- stlf(s, \n",
    "                 h=horizon, \n",
    "                 s.window=3, \n",
    "                 method='arima',\n",
    "                 ic='bic')\n",
    "    }\n",
    "    raw.pred[, j] <- fc$mean\n",
    "  }\n",
    "  for(j in 1:ncol(tr)){\n",
    "    o <- order(crl[j, ], decreasing=TRUE)\n",
    "    score <- sort(crl[j, ], decreasing=TRUE)\n",
    "    if(length(o[score >= level1]) > k){\n",
    "      top.idx <- o[score >= level1]\n",
    "    }else{\n",
    "      top.idx <- o[score >= level2]\n",
    "      top.idx <- top.idx[1:min(length(top.idx),k)]\n",
    "    }\n",
    "    top <- raw.pred[, top.idx]\n",
    "    if (length(top.idx) > 1){\n",
    "      pred <- rowMeans(top)\n",
    "    }else{\n",
    "      pred <- as.numeric(top)\n",
    "    }\n",
    "    pred <- pred * attr(tr.scale, 'scaled:scale')[j]\n",
    "    pred <- pred + attr(tr.scale, 'scaled:center')[j]\n",
    "    test[, j + 1] <- pred\n",
    "  }\n",
    "  test\n",
    "}\n",
    "\n",
    "fourier.arima <- function(train, test, k){\n",
    "  # This model is a regression on k sin/cos pairs of Fourier series terms\n",
    "  # with non-seasonal arima errors. The call to auto.arima() crashes on data\n",
    "  # with too many missing values, or too many identical values, so this \n",
    "  # function falls back to another, more stable method in that case.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  # k - number of sin/cos pair to use\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  horizon <- nrow(test)\n",
    "  for(j in 2:ncol(train)){\n",
    "    if(sum(is.na(train[, j])) > nrow(train)/3){\n",
    "      test[, j] <- fallback(train[,j], horizon)\n",
    "      print(paste('Fallback on store:', names(train)[j]))\n",
    "    }else{\n",
    "      # fit arima model\n",
    "      s <- ts(train[, j], frequency=365/7)\n",
    "      model <- auto.arima(s, xreg=fourier(s, k), ic='bic', seasonal=FALSE)\n",
    "      fc <- forecast(model, h=horizon, xreg=fourierf(s, k, horizon))\n",
    "      test[, j] <- as.numeric(fc$mean)\n",
    "    }\n",
    "  }\n",
    "  test\n",
    "}\n",
    "\n",
    "seasonal.arima.svd <- function(train, test, n.comp){\n",
    "  # Replaces the training data with a rank-reduced approximation of itself\n",
    "  # and then produces seasonal arima forecasts for each store.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # test - An all-zeros matrix of dimension:\n",
    "  #       (number of weeeks in training data) x (number of stores)\n",
    "  #       The forecasts are written in place of the zeros.\n",
    "  # n.comp - the number of components to keep in the singular value\n",
    "  #         decomposition that is performed for preprocessing\n",
    "  #\n",
    "  # returns:\n",
    "  #  the test(forecast) data frame with the forecasts filled in \n",
    "  horizon <- nrow(test)\n",
    "  tr <- preprocess.svd(train, n.comp)\n",
    "  for(j in 2:ncol(tr)){\n",
    "    if(sum(is.na(train[, j])) > nrow(train)/3){\n",
    "      # Use DE model as fallback\n",
    "      test[, j] <- fallback(tr[,j], horizon)\n",
    "      store.num <- names(train)[j]\n",
    "      print(paste('Fallback on store:', store.num))\n",
    "    }else{\n",
    "      # fit arima model\n",
    "      s <- ts(tr[, j], frequency=52)\n",
    "      model <- auto.arima(s, ic='bic', seasonal.test='ch')\n",
    "      fc <- forecast(model, h=horizon)\n",
    "      test[, j] <- as.numeric(fc$mean)\n",
    "    }\n",
    "  }\n",
    "  test\n",
    "}\n",
    "\n",
    "fallback <- function(train, horizon){\n",
    "  # This method is a fallback forecasting method in the case that there are\n",
    "  # enough NA's to possibly crash arima models. It takes one seasonal \n",
    "  # difference, forecasts with a level-only exponential model, and then\n",
    "  # inverts the seasonal difference.\n",
    "  # \n",
    "  # args:\n",
    "  # train - a vector of training data for one store\n",
    "  # horizon - the forecast horizon in weeks\n",
    "  #\n",
    "  # returns:\n",
    "  #  a vector of forecast values\n",
    "  s <- ts(train, frequency=52)\n",
    "  s[is.na(s)] <- 0\n",
    "  fc <- ses(diff(s, 52), h=horizon)\n",
    "  result <- diffinv(fc$mean, lag=52, xi=s[length(s) - 51:0])\n",
    "  result[length(result) - horizon:1 + 1]\n",
    "}\n",
    "\n",
    "preprocess.svd <- function(train, n.comp, d){\n",
    "  # Replaces the training data with a rank-reduced approximation of itself.\n",
    "  # This is for noise reduction. The intuition is that characteristics\n",
    "  # that are common across stores (within the same department) are probably\n",
    "  # signal, while those that are unique to one store may be noise.\n",
    "  #\n",
    "  # args:\n",
    "  # train - A matrix of Weekly_Sales values from the training set of dimension\n",
    "  #         (number of weeeks in training data) x (number of stores)\n",
    "  # n.comp - the number of components to keep in the singular value\n",
    "  #         decomposition\n",
    "  #\n",
    "  # returns:\n",
    "  #  the rank-reduced approximation of the training data\n",
    "  train[is.na(train)] <- 0\n",
    "  z <- svd(train[, 2:ncol(train)], nu=n.comp, nv=n.comp)\n",
    "  s <- diag(z$d[1:n.comp])\n",
    "  train[, 2:ncol(train)] <- z$u %*% s %*% t(z$v)\n",
    "  if (d==1){\n",
    "      print(z)\n",
    "      print('---------------')\n",
    "      print(s)\n",
    "      print('---------------')\n",
    "      print(head(train))\n",
    "  }\n",
    "  train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y <- ts(rnorm(120,0,3) + 1:120 + 20*sin(2*pi*(1:120)/12), frequency=12)\n",
    "# library(ggplot2)\n",
    "# fit=tslm(y~trend+season)\n",
    "# summary(fit)\n",
    "# autoplot(forecast(fit,h=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train <- raw.train()\n",
    "test <- raw.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- grouped.forecast(train, test, 'stlf.svd', model.type='ets', n.comp=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
