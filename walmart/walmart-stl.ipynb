{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import arima\n",
    "import datetime\n",
    "import time\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import stl\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pipeline import *\n",
    "from onehot import *\n",
    "from util import *\n",
    "\n",
    "# load data\n",
    "train_data = pd.read_csv('raw_data/train.csv')\n",
    "test_data = pd.read_csv('raw_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_arima_model(sales, orders, factors=None,speedup=False):\n",
    "    best_r = None\n",
    "    best_o = None\n",
    "#     min_aic=9999999999999\n",
    "    min_bic=9999999999999\n",
    "        \n",
    "    for o in orders:\n",
    "        try:\n",
    "            if speedup:\n",
    "                m=sm.tsa.statespace.SARIMAX(sales,order=o,exog=factors,\n",
    "                         simple_differencing=True, enforce_stationarity=False, enforce_invertibility=False)\n",
    "                    \n",
    "            else:\n",
    "                m=sm.tsa.statespace.SARIMAX(sales,order=o,exog=factors,enforce_stationarity=False)\n",
    "                \n",
    "            r=m.fit(disp=False)\n",
    "            if r.bic < min_bic:\n",
    "                best_r = r\n",
    "                best_o = o\n",
    "#                 min_aic=r.aic\n",
    "                min_bic=r.bic\n",
    "#             print(o,r.bic)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "#             print('%s %s'% (o,e))\n",
    "#             traceback.print_exc()\n",
    "            \n",
    "    return best_r,best_o\n",
    "\n",
    "def make_orders(range_num, seq_num):\n",
    "    if seq_num == 0:\n",
    "        return [[]]\n",
    "    else:\n",
    "        orders=[]\n",
    "        sub_orders=make_orders(range_num,seq_num-1)\n",
    "        for o in sub_orders:\n",
    "            for i in range(range_num):\n",
    "                s=o.copy()\n",
    "                s.append(i)\n",
    "                orders.append(s)\n",
    "        return orders\n",
    "\n",
    "t=time.time()\n",
    "preds=[]\n",
    "depts=sorted(test_data.Dept.unique())\n",
    "# iterate every dept\n",
    "for dept in depts:\n",
    "    if dept < 6:\n",
    "        continue\n",
    "    print('dept %d' % dept)\n",
    "    # transform train to dept, stores(in columns) matrix, index is date fill na with 0\n",
    "    dept_data = train_data[train_data.Dept == dept][['Date','Store','Weekly_Sales']]\n",
    "    if len(dept_data) == 0:\n",
    "        print('no dept data')\n",
    "        continue\n",
    "#     dept_stores = pd.pivot_table(dept_data, values='Weekly_Sales', index='Date', columns='Store', fill_value=0.)\n",
    "#     dept_stores = pd.DataFrame(dept_stores.values,index=pd.DatetimeIndex(dept_stores.index),columns=dept_stores.columns)\n",
    "    \n",
    "    # pca preprocess the sales between stores to filter noise ,use 12 components    \n",
    "#     idxs=dept_stores.index\n",
    "#     cols=dept_stores.columns\n",
    "#     pca = PCA(n_components=12)\n",
    "#     dept_pca = pca.fit_transform(dept_stores)\n",
    "#     dept_restore = pca.inverse_transform(dept_pca)\n",
    "#     dept_stores = pd.DataFrame(dept_restore,index=pd.DatetimeIndex(idxs),columns=cols)\n",
    "    \n",
    "    # iterate every store\n",
    "    stores = sorted(test_data[test_data.Dept == dept].Store.unique())\n",
    "    for store in stores:\n",
    "#         if store != 42:\n",
    "#             continue\n",
    "        \n",
    "        store_test=test_data[np.logical_and(test_data.Store==store,test_data.Dept==dept)][['Date']]\n",
    "        \n",
    "        if len(store_test)>0:\n",
    "            print('store %d'%store)\n",
    "            store_test['Id']=str(store)+'_'+str(dept)+'_'+store_test.Date.astype('U')\n",
    "            store_test['Weekly_Sales']=0\n",
    "            store_test=pd.DataFrame(store_test[['Id','Weekly_Sales']].values,\n",
    "                                    index=pd.DatetimeIndex(store_test.Date),columns=['Id','Weekly_Sales'])\n",
    "            \n",
    "#             store_train = dept_stores.loc[:,store]\n",
    "            store_train = pd.DataFrame(dept_data[dept_data.Store==store].Weekly_Sales.values,\n",
    "                                      index=pd.DatetimeIndex(dept_data[dept_data.Store==store].Date),\n",
    "                                      columns=['Weekly_Sales'])\n",
    "            \n",
    "            \n",
    "            if len(store_train) > 1:\n",
    "                # fill train missing date sales\n",
    "                store_resample = store_train.resample('1W').sum()\n",
    "                store_resample = store_resample.fillna(0)\n",
    "                store_resample.index -= store_resample.index[0]-store_train.index[0]\n",
    "                store_train=store_resample\n",
    "                \n",
    "                # stl the ts\n",
    "                try:\n",
    "                    de = stl.seasonal_decompose(store_train, freq=52)\n",
    "\n",
    "                    # select arima for trend comp\n",
    "                    orders = make_orders(2,3)\n",
    "                    m,o=select_arima_model(de.trend.values,orders)\n",
    "                    if m is not None:\n",
    "                        print('best %s %s',o,m.bic)\n",
    "\n",
    "                        # forecast until test end date\n",
    "\n",
    "                        # test dates may not successive with train dates , and may not continues\n",
    "                        pred_dates=np.array([None]*2)\n",
    "                        pred_dates[0]=store_train.index[-1]+np.timedelta64(1,'W')\n",
    "                        pred_dates[1]=store_test.index[-1]\n",
    "                        pred_data=pd.DataFrame(index=pd.Series(pred_dates))\n",
    "                        pred_data=pred_data.resample('1W').sum()\n",
    "                        pred_data['Weekly_Sales']=0\n",
    "                        # resample change dates adjustment, need change back\n",
    "                        pred_data.index = pred_data.index - (pred_data.index[0]-pred_dates[0])\n",
    "\n",
    "                        # predict continous dates\n",
    "                        fc_data=m.forecast(len(pred_data))\n",
    "                        fc_data=fc_data.reshape(fc_data.shape[0],1)\n",
    "\n",
    "\n",
    "                        # add last season comp to forecasts\n",
    "                        if len(de.seasonal) >= 52 and len(fc_data)<=52:\n",
    "                            fc_data+=de.seasonal.iloc[-52:-52+len(fc_data)].values\n",
    "                        pred_data.Weekly_Sales=fc_data\n",
    "\n",
    "                        # write back to test data\n",
    "                        for date in store_test.index:\n",
    "                            sale_data = pred_data[pred_data.index == date]\n",
    "                            store_test.loc[date,'Weekly_Sales'] = int(sale_data.loc[date,'Weekly_Sales'])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "            preds.append(store_test[['Id','Weekly_Sales']])\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "print('total time %ds'%int(time.time()-t))\n",
    "        \n",
    "# submit\n",
    "result=pd.concat(preds)\n",
    "result.to_csv('output/stl/result.csv',index=False,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sm.nonparametric.lowess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
