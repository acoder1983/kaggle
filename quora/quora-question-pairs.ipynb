{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Imputer\n",
    "from util import *\n",
    "from onehot import LabelBinarizerEx\n",
    "from pipeline import FeaturePipeline, DataFramePipeline\n",
    "from binning import Binner\n",
    "from ensemble import EnsembleStackClassifierEx, StackRegressor\n",
    "from addcols import AddColumns\n",
    "from impute import GroupImputer\n",
    "from ordinal import Ordinar\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_train=pd.read_csv('train.csv')\n",
    "question_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions=question_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions['len1']=questions['len2']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions=questions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = CountVectorizer()  \n",
    "X = vectorizer.fit_transform(list(questions['question1']))\n",
    "transformer = TfidfTransformer()\n",
    "tfidf1 = transformer.fit_transform(X)\n",
    "\n",
    "X = vectorizer.fit_transform(list(questions['question2']))\n",
    "tfidf2 = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(tfidf[0].toarray(),tfidf[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['tfidf1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "help(scipy.sparse.csr.csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "cosine(questions['tfidf1'][0].toarray(),questions['tfidf2'][0].toarray())#,metric='cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "questions['sim']=pd.Series(pairwise_distances(questions['tfidf1'],questions['tfidf2'],metric='cosine',n_jobs=-1))\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pairwise_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [  \n",
    "    'This is the first document.',  \n",
    "    'This is the second second document.',  \n",
    "    'And the third one.',  \n",
    "    'Is this the first document?',  \n",
    "]\n",
    "#将文本中的词语转换为词频矩阵  \n",
    "vectorizer = CountVectorizer()  \n",
    "#计算个词语出现的次数  \n",
    "X = vectorizer.fit_transform(corpus)  \n",
    "#获取词袋中所有文本关键词  \n",
    "word = vectorizer.get_feature_names()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_test=pd.read_csv('test.csv')\n",
    "test_id=question_test['test_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame()\n",
    "result['test_id']=test_id\n",
    "result['is_duplicate']=pd.Series(np.random.randint(1,len(test_id),size=len(test_id))%2)\n",
    "result.to_csv('result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
