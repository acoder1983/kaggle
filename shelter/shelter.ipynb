{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.preprocessing import Imputer\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pipeline import *\n",
    "from onehot import *\n",
    "from util import *\n",
    "from null import *\n",
    "from ordinal import *\n",
    "from impute import *\n",
    "from ensemble import *\n",
    "\n",
    "import multiprocessing\n",
    "jobs=multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('raw_data/train.csv')\n",
    "test_data=pd.read_csv('raw_data/test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_DAYS={'y':365,'m':30,'w':7,'d':1}\n",
    "                \n",
    "def dict_f(x):\n",
    "    items=[]\n",
    "    for a in x.split('/'):\n",
    "        for b in a.split():\n",
    "            items.append(b)\n",
    "    return items\n",
    "\n",
    "train_p=train_data.copy()\n",
    "test_p=test_data.copy()\n",
    "                \n",
    "print(len(train_p.columns),len(test_p.columns))\n",
    "for df in (train_p,test_p):\n",
    "    df['SexuponOutcome']=MixImputer().fit_transform(df[['SexuponOutcome']])\n",
    "    df['AgeuponOutcome']=MixImputer().fit_transform(df[['AgeuponOutcome']])\n",
    "    df['Sex1']=df['SexuponOutcome'].apply(lambda x : x if len(x.split()) == 1 else x.split()[1])\n",
    "    df['Sex2']=df['SexuponOutcome'].apply(lambda x : np.nan if len(x.split()) == 1 else x.split()[0])\n",
    "    df['Age']=df['AgeuponOutcome'].apply(lambda s: int(s.split()[0])*AGE_DAYS[s.split()[1][0]])\n",
    "    df['InDays']=(np.datetime64('2016-02-22')-pd.DatetimeIndex(df['DateTime']).values)/np.timedelta64(1,'D')\n",
    "    df['NameLen']=df['Name'].astype('U').apply(lambda x:len(x))\n",
    "    \n",
    "t=time.time()\n",
    "for fe in ('Breed','Color'):\n",
    "    for i in train_p.index:\n",
    "        items=dict_f(train_p.loc[i,fe])\n",
    "        for itm in items:\n",
    "            c=fe+'_'+itm\n",
    "            if c not in train_p.columns:\n",
    "                train_p[c]=0\n",
    "                test_p[c]=0\n",
    "            train_p.loc[i,c]=1\n",
    "        c=fe+'_len'\n",
    "        train_p.loc[i,c]=len(items)\n",
    "        if c not in test_p.columns:\n",
    "            test_p[c]=0\n",
    "\n",
    "print('time: %ds'%int(time.time()-t))\n",
    "t=time.time()\n",
    "\n",
    "for fe in ('Breed','Color'):\n",
    "    for i in test_p.index:\n",
    "        items=dict_f(test_p.loc[i,fe])\n",
    "        for itm in items:\n",
    "            c=fe+'_'+itm\n",
    "            if c in test_p.columns: \n",
    "                test_p.loc[i,c]=1\n",
    "        test_p.loc[i,fe+'_len']=len(items)\n",
    "\n",
    "print('time: %ds'%int(time.time()-t))            \n",
    "print(len(train_p.columns),len(test_p.columns))\n",
    "\n",
    "OUTCOME_TYPES=['Adoption','Died','Euthanasia','Return_to_owner','Transfer']\n",
    "train_pipeline=DataFramePipeline([\n",
    "    FeaturePipeline('OutcomeType','OutcomeType',Pipeline([('onehot',Ordinar(OUTCOME_TYPES))])),\n",
    "    FeaturePipeline('Name','HasName',Pipeline([('name',NotNull())])),\n",
    "    FeaturePipeline('AnimalType','',Pipeline([('onehot',LabelBinarizerEx(['AnimalType']))])),\n",
    "    FeaturePipeline('Sex1','',Pipeline([('onehot',LabelBinarizerEx(['Sex1']))])),\n",
    "    FeaturePipeline('Sex2','',Pipeline([('onehot',LabelBinarizerEx(['Sex2']))])),\n",
    "    \n",
    "])\n",
    "\n",
    "train_p=train_pipeline.fit_transform(train_p)\n",
    "train_target=train_p['OutcomeType']\n",
    "train_pr=train_p.drop(['AnimalID','Name','DateTime','OutcomeType','OutcomeSubtype','AnimalType','SexuponOutcome','AgeuponOutcome','Breed','Color','Sex1','Sex2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier,LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "base_clfs=[\n",
    "#     LogisticRegression(n_jobs=jobs),\n",
    "#     SVC(probability=True),\n",
    "#     KNeighborsClassifier(n_jobs=jobs,n_neighbors=),\n",
    "#     RandomForestClassifier(n_jobs=jobs),\n",
    "#     GradientBoostingClassifier(),\n",
    "#       AdaBoostClassifier(), \n",
    "#       ExtraTreesClassifier(n_jobs=-1), \n",
    "    XGBClassifier(n_jobs=jobs,random_state=0),\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "def trainModels(train_data, target):\n",
    "    scores=[cross_val_score(clf,train_data,target,scoring='accuracy',cv=3,n_jobs=jobs,verbose=1).mean() for clf in base_clfs]\n",
    "\n",
    "    labels=[c.__class__.__name__[:3] for c in base_clfs]\n",
    "    X=np.arange(len(base_clfs))\n",
    "    bar(X,scores,tick_label=labels,color='rgb')\n",
    "    show()\n",
    "    print(sorted(zip(labels,scores),key=lambda x:x[1],reverse=True))\n",
    "    \n",
    "# trainModels(train_pr,train_target)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_set=[\n",
    "#                 {'C':[0.01,0.1,0.5,1.]},\n",
    "#                 {'C':[1.,10.,],'kernel':['rbf','poly'],'gamma':[0.01,0.1,1.],'coef0':[1.,10.,]},\n",
    "#                 {'n_estimators':[100,500],'max_depth':[10,15]},\n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,300],'max_depth':[5,8]},\n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,200,300]},\n",
    "#                 {'n_estimators':[50,100,200,300],'max_depth':[5,10,15]},\n",
    "                {'learning_rate':[0.01,0.1,1.0],'n_estimators':[500,1000,2000],'gamma':[0.01,0.1,0.5]},\n",
    "#     {'n_neighbors':[3,5,10]},\n",
    "               ]\n",
    "\n",
    "def tuneModels(train_data,target):\n",
    "    results=[]\n",
    "    for i in range(len(base_clfs)):\n",
    "        gs=GridSearchCV(estimator=base_clfs[i],param_grid=param_grid_set[i],scoring='accuracy',n_jobs=jobs,verbose=1,cv=2)\n",
    "        gs.fit(train_data,target)\n",
    "        results.append((gs.best_estimator_,gs.best_score_))\n",
    "    results=sorted(results,key=lambda x:x[1],reverse=True)\n",
    "    return results\n",
    "\n",
    "results=tuneModels(train_pr,train_target)\n",
    "print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t=time.time()\n",
    "# best_clf=GradientBoostingClassifier()\n",
    "# best_clf.fit(train_pr,train_target)\n",
    "# int(time.time()-t),best_clf.score(train_pr,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_clfs=[\n",
    "# #     LogisticRegression(random_state=0,n_jobs=jobs),\n",
    "# #     SVC(probability=True),\n",
    "# #     SGDClassifier(loss='log'),\n",
    "# #     MLPClassifier(),\n",
    "# #     KNeighborsClassifier(n_jobs=jobs),\n",
    "#     RandomForestClassifier(random_state=0,n_jobs=jobs),\n",
    "# #     GradientBoostingClassifier(),\n",
    "# #     AdaBoostClassifier(), \n",
    "#     ExtraTreesClassifier(random_state=0, n_jobs=jobs), \n",
    "#     XGBClassifier(random_state=0,n_jobs=jobs),\n",
    "# ]\n",
    "\n",
    "# from brew.base import Ensemble\n",
    "# from brew.stacking import EnsembleStackClassifier,EnsembleStack\n",
    "# import sklearn\n",
    "\n",
    "# clfs=base_clfs\n",
    "# layer_1 = Ensemble(clfs)\n",
    "# layer_2 = Ensemble([LogisticRegression(random_state=0,n_jobs=jobs)])\n",
    "\n",
    "# stack = EnsembleStack(cv=len(clfs))\n",
    "\n",
    "# stack.add_layer(layer_1)\n",
    "# stack.add_layer(layer_2)\n",
    "\n",
    "# sclf = EnsembleStackClassifierEx(stack)\n",
    "# sclf.fit(train_pr.values,train_target.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from brew.base import Ensemble, EnsembleClassifier\n",
    "# from brew.combination.combiner import Combiner\n",
    "# en=Ensemble(base_clfs)\n",
    "# eclf = EnsembleClassifier(ensemble=en, combiner=Combiner('mean'))\n",
    "# eclf.fit(train_pr.values,train_target.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "xgb=XGBClassifier(n_estimators=1000,gamma=0.1,learning_rate=0.1,n_jobs=jobs)\n",
    "xgb.fit(train_pr,train_target)\n",
    "int(time.time()-t),xgb.score(train_pr,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id=test_data['ID']\n",
    "test_pipeline=DataFramePipeline(train_pipeline.pipelines[1:])\n",
    "test_pp=test_pipeline.transform(test_p)\n",
    "test_pr=test_pp.drop(['ID','Name','DateTime','AnimalType','SexuponOutcome','AgeuponOutcome','Breed','Color','Sex1','Sex2'],axis=1)\n",
    "predicts=xgb.predict_proba(test_pr)\n",
    "submission=pd.concat([test_data[['ID']],pd.DataFrame(predicts,columns=OUTCOME_TYPES)],axis=1)\n",
    "submission.to_csv('output/result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
