{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from brew.base import Ensemble\n",
    "from brew.stacking import EnsembleStackClassifier,EnsembleStack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC,LinearSVR\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from util import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>perc_premium_paid_by_cash_credit</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>Income</th>\n",
       "      <th>Count_3-6_months_late</th>\n",
       "      <th>Count_6-12_months_late</th>\n",
       "      <th>Count_more_than_12_months_late</th>\n",
       "      <th>application_underwriting_score</th>\n",
       "      <th>no_of_premiums_paid</th>\n",
       "      <th>premium</th>\n",
       "      <th>renewal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>7.985300e+04</td>\n",
       "      <td>79756.000000</td>\n",
       "      <td>79756.000000</td>\n",
       "      <td>79756.000000</td>\n",
       "      <td>76879.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57167.166368</td>\n",
       "      <td>0.314288</td>\n",
       "      <td>18846.696906</td>\n",
       "      <td>2.088472e+05</td>\n",
       "      <td>0.248671</td>\n",
       "      <td>0.078188</td>\n",
       "      <td>0.060008</td>\n",
       "      <td>99.067291</td>\n",
       "      <td>10.863887</td>\n",
       "      <td>10924.507533</td>\n",
       "      <td>0.937410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>32928.970160</td>\n",
       "      <td>0.334915</td>\n",
       "      <td>5208.719136</td>\n",
       "      <td>4.965826e+05</td>\n",
       "      <td>0.691468</td>\n",
       "      <td>0.436507</td>\n",
       "      <td>0.312023</td>\n",
       "      <td>0.739799</td>\n",
       "      <td>5.170687</td>\n",
       "      <td>9401.676542</td>\n",
       "      <td>0.242226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7670.000000</td>\n",
       "      <td>2.403000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28640.000000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>14974.000000</td>\n",
       "      <td>1.080100e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.810000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57262.000000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>18625.000000</td>\n",
       "      <td>1.665600e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.210000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>85632.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>22636.000000</td>\n",
       "      <td>2.520900e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.540000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13800.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>114076.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37602.000000</td>\n",
       "      <td>9.026260e+07</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>99.890000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  perc_premium_paid_by_cash_credit   age_in_days  \\\n",
       "count   79853.000000                      79853.000000  79853.000000   \n",
       "mean    57167.166368                          0.314288  18846.696906   \n",
       "std     32928.970160                          0.334915   5208.719136   \n",
       "min         2.000000                          0.000000   7670.000000   \n",
       "25%     28640.000000                          0.034000  14974.000000   \n",
       "50%     57262.000000                          0.167000  18625.000000   \n",
       "75%     85632.000000                          0.538000  22636.000000   \n",
       "max    114076.000000                          1.000000  37602.000000   \n",
       "\n",
       "             Income  Count_3-6_months_late  Count_6-12_months_late  \\\n",
       "count  7.985300e+04           79756.000000            79756.000000   \n",
       "mean   2.088472e+05               0.248671                0.078188   \n",
       "std    4.965826e+05               0.691468                0.436507   \n",
       "min    2.403000e+04               0.000000                0.000000   \n",
       "25%    1.080100e+05               0.000000                0.000000   \n",
       "50%    1.665600e+05               0.000000                0.000000   \n",
       "75%    2.520900e+05               0.000000                0.000000   \n",
       "max    9.026260e+07              13.000000               17.000000   \n",
       "\n",
       "       Count_more_than_12_months_late  application_underwriting_score  \\\n",
       "count                    79756.000000                    76879.000000   \n",
       "mean                         0.060008                       99.067291   \n",
       "std                          0.312023                        0.739799   \n",
       "min                          0.000000                       91.900000   \n",
       "25%                          0.000000                       98.810000   \n",
       "50%                          0.000000                       99.210000   \n",
       "75%                          0.000000                       99.540000   \n",
       "max                         11.000000                       99.890000   \n",
       "\n",
       "       no_of_premiums_paid       premium       renewal  \n",
       "count         79853.000000  79853.000000  79853.000000  \n",
       "mean             10.863887  10924.507533      0.937410  \n",
       "std               5.170687   9401.676542      0.242226  \n",
       "min               2.000000   1200.000000      0.000000  \n",
       "25%               7.000000   5400.000000      1.000000  \n",
       "50%              10.000000   7500.000000      1.000000  \n",
       "75%              14.000000  13800.000000      1.000000  \n",
       "max              60.000000  60000.000000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"raw/train.csv\")\n",
    "test_data=pd.read_csv(\"raw/test.csv\")\n",
    "Y=train_data.renewal\n",
    "results=test_data[['id']].copy()\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_renew_cnt=train_data[train_data.renewal==0].shape[0]\n",
    "# train_data=pd.concat([train_data[train_data.renewal==1].sample(not_renew_cnt),train_data[train_data.renewal==0]])\n",
    "# Y=train_data.renewal\n",
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_premium_paid_by_cash_credit</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>Income</th>\n",
       "      <th>Count_3-6_months_late</th>\n",
       "      <th>Count_6-12_months_late</th>\n",
       "      <th>Count_more_than_12_months_late</th>\n",
       "      <th>application_underwriting_score</th>\n",
       "      <th>no_of_premiums_paid</th>\n",
       "      <th>sourcing_channel</th>\n",
       "      <th>residence_area_type</th>\n",
       "      <th>premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>7.985300e+04</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.314288</td>\n",
       "      <td>18846.696906</td>\n",
       "      <td>2.088472e+05</td>\n",
       "      <td>0.248369</td>\n",
       "      <td>0.078093</td>\n",
       "      <td>0.059935</td>\n",
       "      <td>98.729594</td>\n",
       "      <td>10.863887</td>\n",
       "      <td>0.822799</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>10924.507533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.334915</td>\n",
       "      <td>5208.719136</td>\n",
       "      <td>4.965826e+05</td>\n",
       "      <td>0.691102</td>\n",
       "      <td>0.436251</td>\n",
       "      <td>0.311840</td>\n",
       "      <td>1.864112</td>\n",
       "      <td>5.170687</td>\n",
       "      <td>1.052060</td>\n",
       "      <td>0.489195</td>\n",
       "      <td>9401.676542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7670.000000</td>\n",
       "      <td>2.403000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>14974.000000</td>\n",
       "      <td>1.080100e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.167000</td>\n",
       "      <td>18625.000000</td>\n",
       "      <td>1.665600e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.180000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.538000</td>\n",
       "      <td>22636.000000</td>\n",
       "      <td>2.520900e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.520000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37602.000000</td>\n",
       "      <td>9.026260e+07</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>99.890000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       perc_premium_paid_by_cash_credit   age_in_days        Income  \\\n",
       "count                      79853.000000  79853.000000  7.985300e+04   \n",
       "mean                           0.314288  18846.696906  2.088472e+05   \n",
       "std                            0.334915   5208.719136  4.965826e+05   \n",
       "min                            0.000000   7670.000000  2.403000e+04   \n",
       "25%                            0.034000  14974.000000  1.080100e+05   \n",
       "50%                            0.167000  18625.000000  1.665600e+05   \n",
       "75%                            0.538000  22636.000000  2.520900e+05   \n",
       "max                            1.000000  37602.000000  9.026260e+07   \n",
       "\n",
       "       Count_3-6_months_late  Count_6-12_months_late  \\\n",
       "count           79853.000000            79853.000000   \n",
       "mean                0.248369                0.078093   \n",
       "std                 0.691102                0.436251   \n",
       "min                 0.000000                0.000000   \n",
       "25%                 0.000000                0.000000   \n",
       "50%                 0.000000                0.000000   \n",
       "75%                 0.000000                0.000000   \n",
       "max                13.000000               17.000000   \n",
       "\n",
       "       Count_more_than_12_months_late  application_underwriting_score  \\\n",
       "count                    79853.000000                    79853.000000   \n",
       "mean                         0.059935                       98.729594   \n",
       "std                          0.311840                        1.864112   \n",
       "min                          0.000000                       90.000000   \n",
       "25%                          0.000000                       98.750000   \n",
       "50%                          0.000000                       99.180000   \n",
       "75%                          0.000000                       99.520000   \n",
       "max                         11.000000                       99.890000   \n",
       "\n",
       "       no_of_premiums_paid  sourcing_channel  residence_area_type  \\\n",
       "count         79853.000000      79853.000000         79853.000000   \n",
       "mean             10.863887          0.822799             0.603396   \n",
       "std               5.170687          1.052060             0.489195   \n",
       "min               2.000000          0.000000             0.000000   \n",
       "25%               7.000000          0.000000             0.000000   \n",
       "50%              10.000000          0.000000             1.000000   \n",
       "75%              14.000000          2.000000             1.000000   \n",
       "max              60.000000          4.000000             1.000000   \n",
       "\n",
       "            premium  \n",
       "count  79853.000000  \n",
       "mean   10924.507533  \n",
       "std     9401.676542  \n",
       "min     1200.000000  \n",
       "25%     5400.000000  \n",
       "50%     7500.000000  \n",
       "75%    13800.000000  \n",
       "max    60000.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoders={}\n",
    "drop_cols=['id','renewal']\n",
    "cate_cols=train_data.describe(include=['O']).columns\n",
    "log_cols=['Income','premium']\n",
    "for df in train_data,test_data:\n",
    "    df.application_underwriting_score.fillna(90,inplace=True)\n",
    "#     df.application_underwriting_score-=90\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    for c in drop_cols:\n",
    "        if c in df.columns:\n",
    "            df.drop(c,axis=1,inplace=True)\n",
    "    \n",
    "    for c in cate_cols:\n",
    "#         df[c]=df[c].astype('category')\n",
    "        if c not in lbl_encoders:\n",
    "            lbl_encoders[c]=LabelEncoder()\n",
    "            lbl_encoders[c].fit(df[c])\n",
    "        df[c]=lbl_encoders[c].transform(df[c])\n",
    "        \n",
    "#     for c in log_cols:\n",
    "#         df[c]=df[c].map(np.log)\n",
    "        \n",
    "#     df['prem_total']=df.premium*df.no_of_premiums_paid\n",
    "#     df['cash']=df.perc_premium_paid_by_cash_credit*df.premium\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365684913689323 0.004115113851856034\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier()\n",
    "scores=cross_val_score(lgb,train_data,Y,scoring=score_auc2,cv=5,n_jobs=-1)\n",
    "print(scores.mean(),scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34224, 0.07909654043945769)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(train_data,Y)\n",
    "p=(lgb.predict_proba(test_data)[:,1]*100).astype('int')\n",
    "p.shape[0],np.sum(p<80)/p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06259000914179805"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y==0)/Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tra,x_dev,y_tra,y_dev=train_test_split(train_data,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "\n",
    "model=Sequential([\n",
    "    Dense(32, input_shape=(train_data.shape[1],),activation='tanh'),\n",
    "    Dropout(0.6),\n",
    "    Dense(1,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71867 samples, validate on 7986 samples\n",
      "Epoch 1/3\n",
      "71867/71867 [==============================] - 3s 39us/step - loss: 0.9880 - acc: 0.9380 - val_loss: 1.0860 - val_acc: 0.9319\n",
      "Epoch 2/3\n",
      "71867/71867 [==============================] - 3s 35us/step - loss: 0.9880 - acc: 0.9380 - val_loss: 1.0860 - val_acc: 0.9319\n",
      "Epoch 3/3\n",
      "71867/71867 [==============================] - 2s 34us/step - loss: 0.9880 - acc: 0.9380 - val_loss: 1.0860 - val_acc: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4ae320>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tra,y_tra,validation_data=(x_dev,y_dev),epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7547994994994995 0.006924078215575824\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=200,max_depth=32,n_jobs=-1)\n",
    "scores=cross_val_score(rf,train_data,Y,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "print(scores.mean(),scores.std())\n",
    "# sorted(zip(X.columns,rf.feature_importances_),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\apps\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "x_tra,x_dev,y_tra,y_dev=train_test_split(train_data,Y,test_size=0.1)\n",
    "preds=np.zeros((y_dev.shape[0],2),dtype='int')\n",
    "for i,c in enumerate(best_clfs[:2]):\n",
    "    c.fit(x_tra,y_tra)\n",
    "    preds[:,i]=c.predict(x_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=y_dev[preds[:,0]!=y_dev]\n",
    "p2=y_dev[preds[:,1]!=y_dev]\n",
    "p1.shape[0],p2.shape[0],len(set(p1.index)&set(p2.index))\n",
    "both_idx=set(p1.index)&set(p2.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98    30\n",
       "93    28\n",
       "97    26\n",
       "95    22\n",
       "92    22\n",
       "91    21\n",
       "96    19\n",
       "90    16\n",
       "94    15\n",
       "88    14\n",
       "89    12\n",
       "83    12\n",
       "67    11\n",
       "80    11\n",
       "87    10\n",
       "86    10\n",
       "54    10\n",
       "72    10\n",
       "81     9\n",
       "75     8\n",
       "84     8\n",
       "66     7\n",
       "73     7\n",
       "57     7\n",
       "77     7\n",
       "78     7\n",
       "79     6\n",
       "53     6\n",
       "69     6\n",
       "82     6\n",
       "52     6\n",
       "55     6\n",
       "99     6\n",
       "76     5\n",
       "70     5\n",
       "56     5\n",
       "63     5\n",
       "61     4\n",
       "74     4\n",
       "62     4\n",
       "64     4\n",
       "68     4\n",
       "71     4\n",
       "50     4\n",
       "60     3\n",
       "58     3\n",
       "85     3\n",
       "59     2\n",
       "65     1\n",
       "51     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_renew_idx=Y.loc[both_idx][lambda y:y==0].index\n",
    "wrong_probs=best_clfs[1].predict_proba(train_data.loc[not_renew_idx])[:,1]\n",
    "pd.Series((wrong_probs*100).astype('int')).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_premium_paid_by_cash_credit</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>Income</th>\n",
       "      <th>Count_3-6_months_late</th>\n",
       "      <th>Count_6-12_months_late</th>\n",
       "      <th>Count_more_than_12_months_late</th>\n",
       "      <th>application_underwriting_score</th>\n",
       "      <th>no_of_premiums_paid</th>\n",
       "      <th>sourcing_channel</th>\n",
       "      <th>residence_area_type</th>\n",
       "      <th>premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>7.985300e+04</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "      <td>79853.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.314288</td>\n",
       "      <td>18846.696906</td>\n",
       "      <td>2.088472e+05</td>\n",
       "      <td>0.248369</td>\n",
       "      <td>0.078093</td>\n",
       "      <td>0.059935</td>\n",
       "      <td>98.729594</td>\n",
       "      <td>10.863887</td>\n",
       "      <td>0.822799</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>10924.507533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.334915</td>\n",
       "      <td>5208.719136</td>\n",
       "      <td>4.965826e+05</td>\n",
       "      <td>0.691102</td>\n",
       "      <td>0.436251</td>\n",
       "      <td>0.311840</td>\n",
       "      <td>1.864112</td>\n",
       "      <td>5.170687</td>\n",
       "      <td>1.052060</td>\n",
       "      <td>0.489195</td>\n",
       "      <td>9401.676542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7670.000000</td>\n",
       "      <td>2.403000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>14974.000000</td>\n",
       "      <td>1.080100e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.167000</td>\n",
       "      <td>18625.000000</td>\n",
       "      <td>1.665600e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.180000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.538000</td>\n",
       "      <td>22636.000000</td>\n",
       "      <td>2.520900e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.520000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37602.000000</td>\n",
       "      <td>9.026260e+07</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>99.890000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       perc_premium_paid_by_cash_credit   age_in_days        Income  \\\n",
       "count                      79853.000000  79853.000000  7.985300e+04   \n",
       "mean                           0.314288  18846.696906  2.088472e+05   \n",
       "std                            0.334915   5208.719136  4.965826e+05   \n",
       "min                            0.000000   7670.000000  2.403000e+04   \n",
       "25%                            0.034000  14974.000000  1.080100e+05   \n",
       "50%                            0.167000  18625.000000  1.665600e+05   \n",
       "75%                            0.538000  22636.000000  2.520900e+05   \n",
       "max                            1.000000  37602.000000  9.026260e+07   \n",
       "\n",
       "       Count_3-6_months_late  Count_6-12_months_late  \\\n",
       "count           79853.000000            79853.000000   \n",
       "mean                0.248369                0.078093   \n",
       "std                 0.691102                0.436251   \n",
       "min                 0.000000                0.000000   \n",
       "25%                 0.000000                0.000000   \n",
       "50%                 0.000000                0.000000   \n",
       "75%                 0.000000                0.000000   \n",
       "max                13.000000               17.000000   \n",
       "\n",
       "       Count_more_than_12_months_late  application_underwriting_score  \\\n",
       "count                    79853.000000                    79853.000000   \n",
       "mean                         0.059935                       98.729594   \n",
       "std                          0.311840                        1.864112   \n",
       "min                          0.000000                       90.000000   \n",
       "25%                          0.000000                       98.750000   \n",
       "50%                          0.000000                       99.180000   \n",
       "75%                          0.000000                       99.520000   \n",
       "max                         11.000000                       99.890000   \n",
       "\n",
       "       no_of_premiums_paid  sourcing_channel  residence_area_type  \\\n",
       "count         79853.000000      79853.000000         79853.000000   \n",
       "mean             10.863887          0.822799             0.603396   \n",
       "std               5.170687          1.052060             0.489195   \n",
       "min               2.000000          0.000000             0.000000   \n",
       "25%               7.000000          0.000000             0.000000   \n",
       "50%              10.000000          0.000000             1.000000   \n",
       "75%              14.000000          2.000000             1.000000   \n",
       "max              60.000000          4.000000             1.000000   \n",
       "\n",
       "            premium  \n",
       "count  79853.000000  \n",
       "mean   10924.507533  \n",
       "std     9401.676542  \n",
       "min     1200.000000  \n",
       "25%     5400.000000  \n",
       "50%     7500.000000  \n",
       "75%    13800.000000  \n",
       "max    60000.000000  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8391145257340702 0.004353159321039543\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tra_data=train_data.copy()\n",
    "for c in cate_cols:\n",
    "    tra_data[c]=tra_data[c].astype('category')\n",
    "\n",
    "lgb2 = LGBMClassifier()\n",
    "scores=cross_val_score(lgb2,tra_data,Y,scoring=score_auc,cv=5,n_jobs=-1)\n",
    "print(scores.mean(),scores.std())\n",
    "# sorted(zip(X.columns,lgb.feature_importances_),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC,LinearSVC,LinearSVR\n",
    "\n",
    "# svc=LinearSVR()\n",
    "# svc.fit(x_tra,y_tra)\n",
    "# print(accuracy_score(y_tra,svc.predict(x_tra)),accuracy_score(y_dev,svc.predict(x_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6241289978308169 0.6233843609308618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('application_underwriting_score', 0.001568736917663671),\n",
       " ('age_in_days', 0.0001260914280696475),\n",
       " ('no_of_premiums_paid', 4.228895613794295e-05),\n",
       " ('residence_area_type', 9.259656237019075e-06),\n",
       " ('premium', 8.639554727731608e-06),\n",
       " ('Income', 1.1064006133432162e-06),\n",
       " ('sourcing_channel', -1.3335017742726395e-05),\n",
       " ('perc_premium_paid_by_cash_credit', -4.5445214005235966e-05),\n",
       " ('Count_more_than_12_months_late', -5.38218879105637e-05),\n",
       " ('Count_6-12_months_late', -9.085771571849168e-05),\n",
       " ('Count_3-6_months_late', -0.00012613563718935516)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_tra,y_tra)\n",
    "print(roc_auc_score(y_tra,lr.predict_proba(x_tra)[:,1]),roc_auc_score(y_dev,lr.predict_proba(x_dev)[:,1]))\n",
    "sorted(zip(X.columns,lr.coef_.ravel()),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clfs=[\n",
    "#     LogisticRegression(),\n",
    "#     SVC(probability=True),\n",
    "#     KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "#     GradientBoostingClassifier(),\n",
    "#     AdaBoostClassifier(), \n",
    "#     ExtraTreesClassifier(), \n",
    "#     XGBClassifier(),\n",
    "#     LGBMClassifier(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LGB', 0.8398176834305418)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def trainModels(train_data, target):\n",
    "    scores=[cross_val_score(clf,train_data,target,scoring=score_auc,cv=5,n_jobs=-1,verbose=1).mean() for clf in base_clfs]\n",
    "    \n",
    "    labels=[c.__class__.__name__[:3] for c in base_clfs]\n",
    "    X=np.arange(len(base_clfs))\n",
    "    plt.bar(X,scores,tick_label=labels,color='rgb')\n",
    "    plt.ylim(0.5,1.0)\n",
    "    plt.show()\n",
    "    print(sorted(zip(labels,scores),key=lambda x:x[1],reverse=True))\n",
    "    \n",
    "trainModels(train_data,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LGBMModel in module lightgbm.sklearn:\n",
      "\n",
      "class LGBMModel(sklearn.base.BaseEstimator)\n",
      " |  Implementation of the scikit-learn API for LightGBM.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LGBMModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs)\n",
      " |      Construct a gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      boosting_type : string, optional (default=\"gbdt\")\n",
      " |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      " |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      " |          'goss', Gradient-based One-Side Sampling.\n",
      " |          'rf', Random Forest.\n",
      " |      num_leaves : int, optional (default=31)\n",
      " |          Maximum tree leaves for base learners.\n",
      " |      max_depth : int, optional (default=-1)\n",
      " |          Maximum tree depth for base learners, -1 means no limit.\n",
      " |      learning_rate : float, optional (default=0.1)\n",
      " |          Boosting learning rate.\n",
      " |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
      " |          in training using ``reset_parameter`` callback.\n",
      " |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
      " |      n_estimators : int, optional (default=100)\n",
      " |          Number of boosted trees to fit.\n",
      " |      subsample_for_bin : int, optional (default=50000)\n",
      " |          Number of samples for constructing bins.\n",
      " |      objective : string, callable or None, optional (default=None)\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |          default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      " |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
      " |          Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |          Use this parameter only for multi-class classification task;\n",
      " |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
      " |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
      " |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |          If None, all classes are supposed to have weight one.\n",
      " |          Note that these weights will be multiplied with ``sample_weight`` (passed through the fit method)\n",
      " |          if ``sample_weight`` is specified.\n",
      " |      min_split_gain : float, optional (default=0.)\n",
      " |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |      min_child_weight : float, optional (default=1e-3)\n",
      " |          Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
      " |      min_child_samples : int, optional (default=20)\n",
      " |          Minimum number of data need in a child(leaf).\n",
      " |      subsample : float, optional (default=1.)\n",
      " |          Subsample ratio of the training instance.\n",
      " |      subsample_freq : int, optional (default=0)\n",
      " |          Frequence of subsample, <=0 means no enable.\n",
      " |      colsample_bytree : float, optional (default=1.)\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      reg_alpha : float, optional (default=0.)\n",
      " |          L1 regularization term on weights.\n",
      " |      reg_lambda : float, optional (default=0.)\n",
      " |          L2 regularization term on weights.\n",
      " |      random_state : int or None, optional (default=None)\n",
      " |          Random number seed.\n",
      " |          Will use default seeds in c++ code if set to None.\n",
      " |      n_jobs : int, optional (default=-1)\n",
      " |          Number of parallel threads.\n",
      " |      silent : bool, optional (default=True)\n",
      " |          Whether to print messages while running boosting.\n",
      " |      **kwargs : other parameters\n",
      " |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      " |      \n",
      " |          Note\n",
      " |          ----\n",
      " |          \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      " |      \n",
      " |      Attributes\n",
      " |      ----------\n",
      " |      n_features_ : int\n",
      " |          The number of features of fitted model.\n",
      " |      classes_ : array of shape = [n_classes]\n",
      " |          The class label array (only for classification problem).\n",
      " |      n_classes_ : int\n",
      " |          The number of classes (only for classification problem).\n",
      " |      best_score_ : dict or None\n",
      " |          The best score of fitted model.\n",
      " |      best_iteration_ : int or None\n",
      " |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      " |      objective_ : string or callable\n",
      " |          The concrete objective used while fitting this model.\n",
      " |      booster_ : Booster\n",
      " |          The underlying Booster of this model.\n",
      " |      evals_result_ : dict or None\n",
      " |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      " |      feature_importances_ : array of shape = [n_features]\n",
      " |          The feature importances (the higher, the more important the feature).\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      A custom objective function can be provided for the ``objective``\n",
      " |      parameter. In this case, it should have the signature\n",
      " |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      " |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      " |      \n",
      " |          y_true: array-like of shape = [n_samples]\n",
      " |              The target values.\n",
      " |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The predicted values.\n",
      " |          group: array-like\n",
      " |              Group/query data, used for ranking task.\n",
      " |          grad: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The value of the gradient for each sample point.\n",
      " |          hess: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The value of the second derivative for each sample point.\n",
      " |      \n",
      " |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      " |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      " |      and you should group grad and hess in this way as well.\n",
      " |  \n",
      " |  apply(self, X, num_iteration=0)\n",
      " |      Return the predicted leaf every tree for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      num_iteration : int, optional (default=0)\n",
      " |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape = [n_samples, n_trees]\n",
      " |          The predicted leaf every tree for each sample.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, init_score=None, group=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_class_weight=None, eval_init_score=None, eval_group=None, eval_metric=None, early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      " |      Build a gradient boosting model from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          Input feature matrix.\n",
      " |      y : array-like of shape = [n_samples]\n",
      " |          The target values (class labels in classification, real numbers in regression).\n",
      " |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      " |          Weights of training data.\n",
      " |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      " |          Init score of training data.\n",
      " |      group : array-like or None, optional (default=None)\n",
      " |          Group data of training data.\n",
      " |      eval_set : list or None, optional (default=None)\n",
      " |          A list of (X, y) tuple pairs to use as a validation sets for early-stopping.\n",
      " |      eval_names : list of strings or None, optional (default=None)\n",
      " |          Names of eval_set.\n",
      " |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      " |          Weights of eval data.\n",
      " |      eval_class_weight : list or None, optional (default=None)\n",
      " |          Class weights of eval data.\n",
      " |      eval_init_score : list of arrays or None, optional (default=None)\n",
      " |          Init score of eval data.\n",
      " |      eval_group : list of arrays or None, optional (default=None)\n",
      " |          Group data of eval data.\n",
      " |      eval_metric : string, list of strings, callable or None, optional (default=None)\n",
      " |          If string, it should be a built-in evaluation metric to use.\n",
      " |          If callable, it should be a custom evaluation metric, see note for more details.\n",
      " |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      " |      early_stopping_rounds : int or None, optional (default=None)\n",
      " |          Activates early stopping. The model will train until the validation score stops improving.\n",
      " |          If there's more than one, will check all of them except the training data.\n",
      " |          Validation error needs to decrease at least every ``early_stopping_rounds`` round(s)\n",
      " |          to continue training.\n",
      " |      verbose : bool, optional (default=True)\n",
      " |          If True and an evaluation set is used, writes the evaluation progress.\n",
      " |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      " |          Feature names.\n",
      " |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      " |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      " |          Categorical features.\n",
      " |          If list of int, interpreted as indices.\n",
      " |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      " |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      " |          All values should be less than int32 max value (2147483647).\n",
      " |      callbacks : list of callback functions or None, optional (default=None)\n",
      " |          List of callback functions that are applied at each iteration.\n",
      " |          See Callbacks in Python API for more information.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      Custom eval function expects a callable with following functions:\n",
      " |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      " |      ``func(y_true, y_pred, weight, group)``.\n",
      " |      Returns (eval_name, eval_result, is_bigger_better) or\n",
      " |      list of (eval_name, eval_result, is_bigger_better)\n",
      " |      \n",
      " |          y_true: array-like of shape = [n_samples]\n",
      " |              The target values.\n",
      " |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)\n",
      " |              The predicted values.\n",
      " |          weight: array-like of shape = [n_samples]\n",
      " |              The weight of samples.\n",
      " |          group: array-like\n",
      " |              Group/query data, used for ranking task.\n",
      " |          eval_name: str\n",
      " |              The name of evaluation.\n",
      " |          eval_result: float\n",
      " |              The eval result.\n",
      " |          is_bigger_better: bool\n",
      " |              Is eval result bigger better, e.g. AUC is bigger_better.\n",
      " |      \n",
      " |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      " |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  predict(self, X, raw_score=False, num_iteration=-1, pred_leaf=False, pred_contrib=False, **kwargs)\n",
      " |      Return the predicted value for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      raw_score : bool, optional (default=False)\n",
      " |          Whether to predict raw scores.\n",
      " |      num_iteration : int, optional (default=-1)\n",
      " |          Limit number of iterations in the prediction.\n",
      " |          If <= 0, uses all trees (no limits).\n",
      " |      pred_leaf : bool, optional (default=False)\n",
      " |          Whether to predict leaf index.\n",
      " |      pred_contrib : bool, optional (default=False)\n",
      " |          Whether to predict feature contributions.\n",
      " |      **kwargs : other parameters for the prediction\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      " |          The predicted values.\n",
      " |      X_leaves : array-like of shape = [n_samples, n_trees] or shape [n_samples, n_trees * n_classes]\n",
      " |          If ``pred_leaf=True``, the predicted leaf every tree for each sample.\n",
      " |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape [n_samples, (n_features + 1) * n_classes]\n",
      " |          If ``pred_contrib=True``, the each feature contributions for each sample.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  best_iteration_\n",
      " |      Get the best iteration of fitted model.\n",
      " |  \n",
      " |  best_score_\n",
      " |      Get the best score of fitted model.\n",
      " |  \n",
      " |  booster_\n",
      " |      Get the underlying lightgbm Booster of this model.\n",
      " |  \n",
      " |  evals_result_\n",
      " |      Get the evaluation results.\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Get feature importances.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      Feature importance in sklearn interface used to normalize to 1,\n",
      " |      it's deprecated after 2.0.4 and same as Booster.feature_importance() now.\n",
      " |  \n",
      " |  n_features_\n",
      " |      Get the number of features of fitted model.\n",
      " |  \n",
      " |  objective_\n",
      " |      Get the concrete objective used while fitting this model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 0.8413666191210735)]\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "param_grid_set=[\n",
    "#     {'C':[0.01,0.1,0.5,1.]},\n",
    "#                 {'C':[1.,10.,],'kernel':['rbf','poly'],'gamma':[0.01,0.1,1.],'coef0':[1.,10.,]},\n",
    "    {'n_estimators':[100,200,300],'max_depth':[8,16,32]},\n",
    "                \n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,200,300]},\n",
    "#                 {'n_estimators':[50,100,200,300],'max_depth':[5,10,15]},\n",
    "#     {'n_estimators':[100,200,300],'max_depth':[5,10,15],'gamma':[0.01,0.1,0.5]},\n",
    "#     {'n_estimators':[100,200],\n",
    "#      'learning_rate':[0.01,0.05,0.1],\n",
    "#      'subsample':[1.,0.8],'colsample_bytree':[1.,0.8]\n",
    "#     },\n",
    "               ]\n",
    "\n",
    "def tuneModels(train_data,target):\n",
    "    results=[]\n",
    "    for i in range(len(base_clfs)):\n",
    "        gs=GridSearchCV(estimator=base_clfs[i],param_grid=param_grid_set[i],scoring=score_auc,n_jobs=-1,verbose=1,cv=5)\n",
    "        gs.fit(train_data,target)\n",
    "        results.append((gs.best_estimator_,gs.best_score_))\n",
    "    print(sorted(results,key=lambda x:x[1],reverse=True))\n",
    "    return results\n",
    "\n",
    "tuned_r=tuneModels(train_data,Y)\n",
    "best_clfs=[r[0] for r in tuned_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clfs=[RandomForestClassifier(n_estimators=200,max_depth=8,n_jobs=-1),\n",
    "           LGBMClassifier(n_estimators=100,learning_rate=0.04,colsample_bytree=0.8),\n",
    "           GradientBoostingClassifier(n_estimators=100,learning_rate=0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8530097094267832 0.8532954110810091\n"
     ]
    }
   ],
   "source": [
    "layer_1 = Ensemble(best_clfs)\n",
    "layer_2 = Ensemble([LGBMClassifier()])\n",
    "\n",
    "stack = EnsembleStack(cv=3)\n",
    "\n",
    "stack.add_layer(layer_1)\n",
    "stack.add_layer(layer_2)\n",
    "\n",
    "sclf = EnsembleStackClassifier(stack)\n",
    "\n",
    "x_tra,x_tst,y_tra,y_tst=train_test_split(train_data,Y,test_size=0.1)\n",
    "sclf.fit(x_tra.values,y_tra.values)\n",
    "print(roc_auc_score(y_tra,sclf.predict_proba(x_tra)[:,1]),roc_auc_score(y_tst,sclf.predict_proba(x_tst)[:,1]))\n",
    "# scores=cross_val_score(sclf,train_data.values,Y,scoring=score_auc,cv=5,n_jobs=-1)\n",
    "# print(scores.mean(),scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\apps\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\apps\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5332432752688814\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "x_tra,x_dev,y_tra,y_dev=train_test_split(train_data,Y,test_size=0.1)\n",
    "preds=[]\n",
    "for c in best_clfs:\n",
    "    c.fit(x_tra,y_tra)\n",
    "    preds.append(c.predict(x_tra))\n",
    "lgb_en=LGBMClassifier()\n",
    "lgb_en.fit(np.c_[preds].T,y_tra)\n",
    "\n",
    "preds2=[]\n",
    "for c in best_clfs:\n",
    "    preds2.append(c.predict(x_dev))\n",
    "print(roc_auc_score(y_dev,lgb_en.predict_proba(np.c_[preds2].T)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile util.py\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def score_auc(c,x,y):\n",
    "    p=c.predict_proba(x)[:,1]\n",
    "    return roc_auc_score(y,p)\n",
    "\n",
    "def score_auc2(c,x,y):\n",
    "    p=c.predict_proba(x)[:,1]\n",
    "    p[p<0.8]=0\n",
    "    return roc_auc_score(y,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1361c400>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd81eXd//HXJ3tAFgkhJIEAsjeErWidaBVQHOAAq4g4qrZ321vb/mz1vltrhxsQUFqgilQERQtuEWUakD0TVkKALLIHGdfvj3Nym4aEnISTfM/4PB+P8+Dke64k73MIH65c5/P9XmKMQSmllGfxsTqAUkop59PirpRSHkiLu1JKeSAt7kop5YG0uCullAfS4q6UUh7I0uIuIotEJEtE9jgw9kUR2WG/HRKR/LbIqJRS7kis7HMXkfFAMbDEGDOgGZ/3U2CoMea+VgunlFJuzNKZuzFmPZBX95iI9BCRj0Vkm4h8IyJ9GvjUacCyNgmplFJuyM/qAA1YAMw2xhwWkVHAXODK2gdFpCvQDfjSonxKKeXyXKq4i0g7YCzwrojUHg6sN2wqsMIYU92W2ZRSyp24VHHHtkyUb4wZcoExU4FH2iiPUkq5JZdqhTTGFAJHReQ2ALEZXPu4iPQGIoFNFkVUSim3YHUr5DJshbq3iGSIyP3AXcD9IrIT2AtMqvMp04B3jF7KUimlLsjSVkillFKtw6WWZZRSSjmHZW+oRkdHm6SkJKu+vVJKuaVt27blGGNimhpnWXFPSkoiJSXFqm+vlFJuSUSOOzJOl2WUUsoDaXFXSikPpMVdKaU8kMPFXUR8ReR7EfmogccCRWS5iKSKyBYRSXJmSKWUUs3TnJn748D+Rh67HzhrjLkEeBF4/mKDKaWUajmHiruIJAA/Bt5oZMgkYLH9/grgKqlz5S+llFJty9GZ+0vAr4CaRh6PB9IBjDFVQAHQof4gEZklIikikpKdnd2CuEoppRzRZJ+7iNwIZBljtonIFY0Na+DYedc1MMYswHa9dpKTk/W6B62kpsaQWVBGxtkyzpacI6/0HIVlVdQYQ02N7WUPCfSjfaAf7YP86BgWSHxECB3bB+Ljo79wKeUJHDmJaRwwUURuAIKAMBH5pzHm7jpjMoBEIENE/IBw6u2wpFqHMYajOSWkHDtLyvE8dp8s5GhOMeWVjf2S1Th/XyEhMoTese3pE9eevnFhDEoIJy48uBWSK6VaU5PF3RjzFPAUgH3m/ot6hR1gNTAD2xUebwW+1Cs3th5jDNtPnOXjPaf5bN8ZjuWWAhAe7M/gxAjG9uhA95hQukSF0CE0kKjQAMKD/fH1EXzE9itVaUU1heWVFJZXklVYQUZ+GSfPlnE8t4QDp4v4ZN9pav8GEyKDGdktipFJUYy7JJrEqBDrnrxSyiEtvvyAiDwLpBhjVgNvAktFJBXbjH2qk/KpOvJLz7FiWwbLtp4gLbsEf19hTI9o7r+0G6O7d6BHTDuHl1XCQ3wID/EHoH/n8x8vqaji4Jkivj+Rz3dH8/j6YDYrt58EoGfHdlzZtyNX9u7I8K6R+Pnq6RJKuRrLLvmbnJxs9NoyjskuquCNb46wdPNxSs9VM7RLBNNGdOH6gZ1oH+TfJhmMMaRlF7PuYDZfHcxiy5E8qmoMHUID+PGgOCYO7sywLpG6Zq9UKxORbcaY5CbHaXF3XWXnqpm3LpUF3xzhXFUNEwd35sHLe9A3LszqaBSVV/LN4Rz+vesUn+8/Q0VVDfERwUwc0pnbkxPpFh1qdUSlPJIWdze3dvcp/uejfWQWlHPT4M787OqedI9pZ3WsBhVXVPHp3tOs3pnJN4dzqK4xjO3RgWkju3Bt/1gC/XytjqiUx9Di7qbyS8/x/z7Yy4c7M+kbF8YzE/szsluU1bEcllVYzrv29wUyzpYRFRrA7cmJzBjbVbtulHICLe5uaFNaLj9bvoOc4goev6onD13Rw23frKypMXybmsPbW07w6b7T+Ihw0+DO3H9pNwbEh1sdTym35Whxt2yzDvUDYwz/2HiM//33frp2CGHV9HEMTHDvAujjI4zvFcP4XjGk55Xy9w3HWP7dCVZ9f5LR3aN4cHwPrugdg16lQqnWoTN3i52rquHXq3azYlsGV/eN5cU7BrdZB0xbKyyvZPnWdP6+4SiZBeUMjA/nsat6cnXfjlrklXKQLsu4gdJzVcz+53bWH8rmsat68sRVPb2ilbCyuoZV20/y2lepnMgrpV9cGI9ddQnX9uvkFc9fqYuhxd3FFZRW8pN/bGVHej7P3TKQO0Z0sTpSm6usruGDHZnM+SqVozkl9OnUnl9e15sr++hMXqnGaHF3YUXlldz1xhYOnCrilWlDmDAgzupIlqqqruGjXad46fNDHMstZURSJE9e34fhXd2nS0iptuJocXfPVgw3Vnaumvv/kcK+zELm3jXM6ws7gJ+vD5OHxvPZzy/nfycP4FhuKVPmbeKBJSkcPlNkdTyl3JIW9zZUVV3DQ29tI+V4Hi/eMYSr+8VaHcml+Pv6cPfornz9yyv45XW92ZyWy3Uvree/V+wiq6jc6nhKuRUt7m3omQ/3se5gNn+4eSA3DW7gal0KgJAAPx750SWs/9WPuG9cN1Z+n8GVf/2a+V+nUVFVbXU8pdyCFvc2snjjMZZuPs6D47szbaT3vXnaEpGhAfz2xn58+rPLGd09iufWHuDaF9fz2b4z6BWllbowLe5tYGNqDs98uJer+8byqwl9rI7jdrpFh/LGjBEsvm8k/r4+PLAkhemLtnJI1+OVapQW91aWVVTOY+/soHtMO16eOgRf7eNusct7xbD28cv43U392Jmez/Uvf8Mf1+ynpKLK6mhKuRwt7q2ousbwxDs7KK6oZM6dwwgN1Ks9XCx/Xx9+Mq4b6375I24bnsCC9Ue45oWv+XTvaaujKeVSmizuIhIkIltFZKeI7BWRZxoYc6+IZIvIDvttZuvEdS9zv0plY1ouz04cQO9O7a2O41GiQgP405RBrJg9hvZB/sxauo2Zi1PIOFtqdTSlXIIjM/cK4EpjzGBgCDBBREY3MG65MWaI/faGU1O6oT0nC3j5i8NMGtKZ25ITrI7jsZKTovjosUv59Q192JCawzUvrOf1r9OorG7+BuFKeZImi7uxKbZ/6G+/aavCBZyrquEX7+4kMjSAZyb211PpW5m/rw+zxvfg8/+6nMt6RvOntQe46dVv2ZWRb3U0pSzj0Jq7iPiKyA4gC/jMGLOlgWFTRGSXiKwQkcRGvs4sEUkRkZTs7OyLiO3aXvsqlQOni3ju5oFEhARYHcdrxEcEs2B6MgunJ3O29ByT52zgubX7Ka/U3njlfRwq7saYamPMECABGCkiA+oN+RBIMsYMAj4HFjfydRYYY5KNMckxMTEXk9tlHTxdxNyvUrl5aLyegWqRa/rF8unPLuf25ETmf32EG17+hu+O5VkdS6k21axuGWNMPrAOmFDveK4xpsL+4UJguFPSuRljDE9/sId2QX48fWM/q+N4tfBgf/40ZRBvzRxFZU0Nt8/fxO8+2EOxtk0qL+FIt0yMiETY7wcDVwMH6o2pe/WricB+Z4Z0F6t3ZrLlaB6/vK43kaG6HOMKxl0SzSdPjOfesUks2Xyc615cz/pDnrskqFQtR2buccBXIrIL+A7bmvtHIvKsiEy0j3nM3ia5E3gMuLd14rqu4ooq/rhmPwPiw5jqhddmd2UhAX787qb+rJg9hiB/H6Yv2sqvV+3Wk5+UR9PruTvJnz8+wNx1aax8eCzDukRaHUc1oryymhc/O8SCb46QGBnCC7cPJjlJrxuv3Idez70NnSksZ9GGo0wa0lkLu4sL8vflqRv6snzWGAyG2+Zv4rm1+/Vqk8rjaHF3gpc+P0x1jeG/rultdRTloJHdolj7+HimjujC/K+PMOm1DezNLLA6llJOo8X9Ih3JLuZfKencObILXTqEWB1HNUO7QD+eu2Ugf793BLkltr74OV+lUqVntyoPoMX9Iv3t00ME+vnw6JU9rY6iWuhHfTry6RPjubZ/J/7yyUFun7+JE7l6jRrl3rS4X4SDp4v49+5T3H9pN2LaB1odR12EyNAA5tw5jJenDuFwVjE3vPIN739/0upYSrWYFveLMHddKiEBvtw3rpvVUZSTTBoSz9rHL6NvXHueWL6Dny3fQVF5pdWxlGo2Le4tdCynhA93ZnL36K56wpKHSYgMYdkDo/n5Nb1YvTOTG175hu0nzlodS6lm0eLeQq9/nYafrw8zL9VZuyfy8/Xhsat68q8HR2MM3Pb6Jl79wtYVpZQ70OLeApn5Zby3PYM7khPpGBZkdRzVioZ3jWLN45fx44Fx/O2zQ0xbsJmT+WVWx1KqSVrcW2DxxmPUGJg1vrvVUVQbCAvy5+WpQ3jh9sHszSzg+pfWs3b3KatjKXVBWtybqfRcFcu2nuC6/rEkRmlfu7cQEW4ZlsCaxy+jW0w7HnprO09/sEevFa9clhb3Zlr1/UkKy6u4d6yutXujrh1CeffBMcy8tBtLNh1nyryNHMspsTqWUufR4t4Mxhj+seEY/TuHMSJJryHjrQL8fPjtjf14Y3oyGWfLuPHVb/lwZ6bVsZT6D1rcm+Hb1BwOZxXzk3HddF9UxdX9Ylnz+GX0jG3HT5d9z29W7dZlGuUytLg3w+KNx4huF8BNg+OaHqy8QnxEMP96cAwPju/OW1tOcPPcjRzJLm76E5VqZVrcHXS6oJwvD2RxW3IigX6+VsdRLsTf14enbujLonuTOVVQxk2vfssHO/TSBcpajmyzFyQiW0Vkp323pWcaGBMoIstFJFVEtohIUmuEtdJ72zOoMXB7cqLVUZSLurJPLGseu4y+cWE8/s4Onlq5S5dplGUcmblXAFcaYwYDQ4AJIjK63pj7gbPGmEuAF4HnnRvTWjU1huXfpTO6exTdokOtjqNcWOeIYJbNGs1DV/Rg2dZ0pszbqFeYVJZosrgbm9pFRH/7rf452JOAxfb7K4CrxIPecdx8NJcTeaW6N6pyiL+vD/89oQ+L7k0mPa+UG1/9hi/2n7E6lvIyDq25i4iviOwAsrBtkL2l3pB4IB3AGFMFFAAdGvg6s0QkRURSsrPdZwf65d+lExbkx4QBnayOotzIlX1i+einl5EYFcL9i1P46ycH9do0qs04VNyNMdXGmCFAAjBSRAbUG9LQLP28n2JjzAJjTLIxJjkmJqb5aS1QUFrJ2j2nmTw0niB/fSNVNU+XDiG899BY7khO5LWvUpmxaCu5xRVWx1JeoFndMsaYfGAdMKHeQxlAIoCI+AHhQJ4T8lnu472nOFdVw5RhCVZHUW4qyN+X528dxPNTBrL1WB43vvqtXkJYtTpHumViRCTCfj8YuBo4UG/YamCG/f6twJfGGI/4/fODHZl0iw5lUEK41VGUm7tjRBdWPjQWP1/hjvmbWLLpGB7yz0S5IEdm7nHAVyKyC/gO25r7RyLyrIhMtI95E+ggIqnAz4EnWydu2zpTWM6mI7lMHNxZz0hVTjEgPpyPHr2My3rG8PQHe3li+Q5Kz1VZHUt5IL+mBhhjdgFDGzj+dJ375cBtzo1mvQ93ZmIMTBrS2eooyoOEh/jzxvRk5q5L5W+fHWL/qULm3T2cHjHtrI6mPIieoXoBH+zIZFBCON31H51yMh8f4dEre7LkvpHkFJ9j0msb+Gyftksq59Hi3oi07GJ2nyxg4mCdtavWc1nPGD786aV0iw7lgSUpvPT5IWq0XVI5gRb3Rny08xQicJMWd9XK4iOCeXf2GG4ZFs9Lnx9m1tJtFJZXWh1LuTkt7o34eO9pkrtGEqt7pKo2EOTvy99uG8zvb+rHVwezmDxnA6lZenVJ1XJa3BtwIreU/acKua6/npGq2o6IcO+4brw1cxQFpZVMnrOBT/eetjqWclNa3Bvwif0flBZ3ZYXR3Tvw4U8vpXtMKLOWbuOFz3QdXjWfFvcGfLL3NP3iwnQDbGWZzvZNQG4dnsArXxxm1tIUXYdXzaLFvZ6sonK2nTirs3ZluSB/X/5y6yCendSfdQezmfzaBlKziqyOpdyEFvd6Ptt3BmPgugGxVkdRChFh+pgk3po5isLySibP2fh/y4ZKXYgW93o+2XuGrh1C6B3b3uooSv2fUfZ1+B4xoTy4dBsv6jq8aoIW9zpKKqrYlJbDtf1i9VoyyuXEhQez/MExTBmWwMtfHOaRt7frdWlUo7S417EhNYfKasOPene0OopSDQry9+Wvtw3itz/uyyd7TzNl3iYyzuo2fup8WtzrWHcom9AAX5KToqyOolSjRISZl3Vn0b0jyDhbyqTXNrD1qEdsn6CcSIu7nTGGrw9mM+6SaAL89GVRru+K3h15/5FxhAf7c9cbm1m29YTVkZQL0SpmdzirmJP5ZVyhSzLKjfSIaceqh8cxpkc0T63cze8+2ENVdY3VsZQL0OJut+5gFgBX9HaPvV2VqhUe4s+iGcnMvLQbizcdZ8bft5Jfes7qWMpijmyzlygiX4nIfhHZKyKPNzDmChEpEJEd9tvTDX0tV7buYDa9Y9vTOSLY6ihKNZufrw+/vbEff7l1EN8dPcukORs4fEZPePJmjszcq4D/Msb0BUYDj4hIvwbGfWOMGWK/PevUlK2suKKK747l6axdub3bkhNZNms0JRXV3Dx3I1/s1w1AvFWTxd0Yc8oYs91+vwjYD8S3drC2tNHeAnm5FnflAYZ3jWT1o+NIig5h5pIU5q1L0424vVCz1txFJAnbfqpbGnh4jIjsFJG1ItK/kc+fJSIpIpKSnZ3d7LCtZWNaLkH+PgzvGml1FKWconNEMO8+OJYfD4zj+Y8P8MTyHZRXVlsdS7Uhh4u7iLQD3gOeMMYU1nt4O9DVGDMYeBV4v6GvYYxZYIxJNsYkx8S4zix5Y1oOI5KiCPTztTqKUk4THODLq9OG8otre/HBjkzuWLCZrKJyq2OpNuJQcRcRf2yF/S1jzMr6jxtjCo0xxfb7awB/EYl2atJWkl1UwaEzxYzt4RZxlWoWEdtG3PPvGc6h00VMfm0D+zLrz82UJ3KkW0aAN4H9xpgXGhnTyT4OERlp/7q5zgzaWjYdscUc26ODxUmUaj3X9e/Eu7PHUGPg1tc38tk+faPV0zkycx8H3ANcWafV8QYRmS0is+1jbgX2iMhO4BVgqnGTd3A2peXQPsiP/p3DrI6iVKsaEB/OB4+O45KO7Zi1NIUF6/WNVk/m19QAY8y3wAUvkWiMeQ14zVmh2tKG1FxGdeuAn6+ez6U8X2xYEMtnjeEX7+7kj2sOkJZVwv9MHqCX3PBAXv03mp5Xyom8UsZdoksyynvUvtH62JWXsDwlnXve3MLZEj2j1dN4dXH/Yb1d30xV3sXHR/j5tb156Y4hfH8in8lzN5CaVWx1LOVE3l3c03LpEBpAr9h2VkdRyhKTh8bbz2it4ua5G/j2cI7VkZSTeHVx33o0j1Hdo3TXJeXVhneNZNXD4+gcHsyMv2/ln5uPWx1JOYHXFvfM/DJO5peR3FU35lAqMSqEFQ+NYXzPaH77/h6e+XCvXjrYzXltcU85fhaAEbrrklIAtA/y540ZI7hvXDf+vuEYM5ekUFReaXUs1ULeW9yP5RES4EvfuPZWR1HKZfj6CE/f1I8/3jyQbw/nMGXeRtLzdI9Wd+TFxf0sw7pEan+7Ug24c1QXltw3ktMF5Uyes4Ftx3WPVnfjlZWtsLySA6cLSU7Sq0Aq1Zixl0Tz/iPjaB/kx7SFW/hoV6bVkVQzeGVx//5EPjVG19uVakr3mHasfHgcgxPCefTt75m7LlUvWeAmvLK4pxzLw9dHGJIYYXUUpVxeVGgA/5w5iklDOvPnjw/y5Hu7qdROGpfX5LVlPNF3x/LoFxdGaKBXPn2lmi3Qz5eX7hhC1w6hvPLFYTLyS5l713DCg/2tjqYa4XUz98rqGnak5+t6u1LNJCL8/Jpe/PW2wWw9mset2knj0ryuuB84VUR5ZY1uqadUC906PIHF943kTGE5N8/dwI70fKsjqQZ4XXHfkWH7QdT1dqVabmyPaFY+PI7gAF/umL+JtbtPWR1J1eN1xX1nej7R7QKIjwi2OopSbu2Sju14/+Fx9O8cxsNvb2f+17r5hytxZJu9RBH5SkT2i8heEXm8gTEiIq+ISKqI7BKRYa0T9+LtTM9ncEKEXixMKSfo0C6Qtx8YzQ0D43hu7QF+vWqPdtK4CEfaRaqA/zLGbBeR9sA2EfnMGLOvzpjrgZ722yhgnv1Pl1JUXklqdjE3De5sdRSlPEaQvy+vTh1K16gQ5q5LI+NsKXPuGkZYkHbSWKnJmbsx5pQxZrv9fhGwH4ivN2wSsMTYbAYiRCTO6Wkv0u6MAoyBwbrerpRT+fgIv5rQhz9PGcSmtFxum7eJk/llVsfyas1acxeRJGAosKXeQ/FAep2PMzj/PwBEZJaIpIhISnZ2dvOSOkHtm6mDE8Lb/Hsr5Q1uH5HI4vtGkllQxuQ5G9iVoZ00VnG4uItIO+A94AljTGH9hxv4lPPeWTHGLDDGJBtjkmNiYpqX1Al2pueT1CGEiJCANv/eSnmLcZdEs/KhsQT6+XD7/E18sve01ZG8kkPFXUT8sRX2t4wxKxsYkgEk1vk4AXC5qwztTC/QJRml2kDP2PasengcvTuFMfuf23jjmyPaSdPGHOmWEeBNYL8x5oVGhq0Gptu7ZkYDBcYYl2p8PV1QzunCcgYnaHFXqi3EtA/knQdGM6F/J/733/t55sN9VNdogW8rjnTLjAPuAXaLyA77sV8DXQCMMa8Da4AbgFSgFPiJ86NenJ216+06c1eqzQQH+DLnzmE8t3Y/C785ysn8Ml6ZOpTgAF+ro3m8Jou7MeZbGl5TrzvGAI84K1Rr2JWRj6+P0L9zmNVRlPIqPj7Cb37cj/iIYJ75aB9TF27mzRnJRLcLtDqaR/OaM1T3ZhbSs2M7gvx1xqCUFe4d1435dw/n4OlCbpm7kSPZxVZH8mheVdz76axdKUtd278Tyx4YTUlFFbfM20jKMd2+r7V4RXHPKionu6iCfnFa3JWy2tAukax8eCyRIQHc+cYW/r3LpXovPIZXFPd9mba2/P6d9eQlpVxB1w6hrHxoLIPiw3nk7e0sXK+tks7mFcV9r72467KMUq4j0r59348HxvGHNfv5/eq92irpRF6xz9y+U4UkRgXrlmBKuZggf19enTaU+MhgFqw/QmZBubZKOolXzNz3ZRbqertSLsrHR/j1DX15ZmJ/vth/hqkLN5NTXGF1LLfn8cW9uKKKozklut6ulIubMTaJ1+2tkjfP3UCatkpeFI8v7vtP1b6ZqjN3pVzdtf078c6sMZRWVDNl3ka+01bJFvP44q6dMkq5lyGJEax6eBxRIQHcpa2SLebxxX1vZgFRoQHEhumpzkq5iy4dQnivTqvkgvW6P2tzeUFxL6R/5zDdM1UpN1O3VfKPaw5oq2QzeXRxr6qu4XBWMX21U0Ypt1TbKjlrfHcWbzrOg0u3UXquyupYbsGji/vxvFLOVdXQO7a91VGUUi1U2yr57KT+fHngDNMWaKukIzy6uB88XQRA705a3JVyd9PHJDH/nmQOninilrkbOZpTYnUkl+bxxV0ELunYzuooSiknuKZfLMseGE1xRRVT5m3k+xNnrY7kshzZZm+RiGSJyJ5GHr9CRApEZIf99rTzY7bMoTNFJHUI1Wu4K+VBhnaJ5L2HxtIu0I9pCzfzxf4zVkdySY7M3P8BTGhizDfGmCH227MXH8s5Dp4polesztqV8jTdokN576Gx9IptzwNLUnh7ywmrI7mcJou7MWY94HaniZVXVnMsp0TfTFXKQ8W0D2TZA6MZ3yuGX6/azQufHtRe+DqcteY+RkR2ishaEenf2CARmSUiKSKSkp2d7aRv3bC07GJqDPTSN1OV8lihgX4snJ7M7ckJvPJlKr9asYvK6hqrY7kEZ1zydzvQ1RhTLCI3AO8DPRsaaIxZACwASE5ObtX/Yg+dsXfK6MxdKY/m7+vD81MGERcezMtfHCarqIK5dw0jNNArrmjeqIueuRtjCo0xxfb7awB/EYm+6GQX6eDpYvx9haToUKujKKVamYjws2t68adbBvJtag5TF2wmu8i7e+EvuriLSCexn9svIiPtXzP3Yr/uxTp0pogeMe3w9/Xobk+lVB1TR3Zh4fThpGYVc8u8DRzx4ssGO9IKuQzYBPQWkQwRuV9EZovIbPuQW4E9IrITeAWYalzgXY2Dp4vopUsySnmdK/vEsmzWaErslw3e7qW98I50y0wzxsQZY/yNMQnGmDeNMa8bY163P/6aMaa/MWawMWa0MWZj68e+sKLySk7ml+mZqUp5qSGJEax8aCxhwf7cuXAzn+/zvl54j1yzOJxl+1VMZ+5Kea8key9879j2zFqawltbjlsdqU15ZHFPtRf3nnrZAaW8WnS7QJbNGs3lvWL4zao9/M2LeuE9srinZRcT4OtDQmSw1VGUUhYLCbD1wk8dkcirX6bySy/phffIRtC0rBKSokPw004ZpRTg5+vDc7cMpFN4EC99buuFn+fhvfAeWf2O5BTTPVqXZJRSPxARnri6F89PGciG1BzuWLCJrKJyq2O1Go8r7pXVNZzILaVHRz15SSl1vjtGdOGN6cmkZZUwZd5G0jy0F97jivvx3FKqagw9YnTmrpRq2I/6dOSdWaMprajm1nkb2Xbc83rhPa64156R1l2Lu1LqAgYnRrDy4bGE23vhP9172upITuVxxT0t27b1VvcYXZZRSl1Y1w62Xvg+cWHM/uc2lm72nF54jyvuR7KLiWkfSFiQv9VRlFJuoEO7QJY9MIof9e7I/3vfc3rhPa64p2UX00Nn7UqpZggJ8GP+PcO5I9nWC//ke7upcvNeeI9q8jTGkJZdwo2D4qyOopRyM36+PvxpykBiwwJ55ctUcooreO3OYQQHuOcezB41c88rOUdBWaW+maqUahER4efX9uZ/Jg/gy4NZ3PnGZs6WnLM6Vot4VHGvfTNVl2WUUhfjntFdmXfXMPZmFjLl9Y1knC21OlKzeVhxt7VBao+7UupiTRgQxz/vH0VOUQVT5m3kwOlCqyMXL6xuAAAMgklEQVQ1i0cV9yPZxQT6+RAfoRcMU0pdvJHdonh39lgE4bbXN7H5iOWbzDnMkZ2YFolIlojsaeRxEZFXRCRVRHaJyDDnx3TMkewSukWH4uMjVkVQSnmY3p3a897DY4kNC2L6m1tZs/uU1ZEc4sjM/R/AhAs8fj3Q036bBcy7+Fgtcyy3hKQOut6ulHKu+IhgVswew8CEcB55eztLNh2zOlKTHNlmbz2Qd4Ehk4AlxmYzECEibd6LWF1jSM8ro2t0SFt/a6WUF4gICeCtmaO4qk8sT3+wl798csClT3Zyxpp7PJBe5+MM+7HziMgsEUkRkZTs7GwnfOsfnCoo41x1jc7clVKtJsjfl9fvHsa0kYnM+SqNX63Y5bInOzmjuDe0wN3gf2fGmAXGmGRjTHJMTIwTvvUPjufaWpW6dtCZu1Kq9fj5+vDHmwfy+FU9eXdbBrOWbqP0XJXVsc7jjOKeASTW+TgByHTC122WY7m2HneduSulWpuI8LNrevGHmwew7mAWdy7cQp6LnezkjOK+Gphu75oZDRQYY9r87eTjuaUE+PnQKSyorb+1UspL3TWqK/PuHs6+U4Xc+vpG0vNc52QnR1ohlwGbgN4ikiEi94vIbBGZbR+yBjgCpAILgYdbLe0FHM8toUtUiLZBKqXa1HX9O/HWzB9OdtqX6RonOzV54TBjzLQmHjfAI05L1ELHc0tJ0vV2pZQFRiRFseKhscxYtJU75m9i/vThjO0RbWkmjzhD1RjDsdwSuup6u1LKIr1i2/PeQ2PpFB7EvYu+49+7rD3ZySOKe1ZRBeWVNTpzV0pZqnNEMO/OHsPgxHAeXbadf2w4alkWjyjux3JsnTI6c1dKWS0iJICl94/imr6x/P7Dffz5Y2tOdvKI4l7b465tkEopVxDk78u8u4dz56guzF2Xxi/e3UVlG5/s5BE7MR3LLcHPR+gcoW2QSinX4Osj/GHyAGLbB/Hi54fILalg7l3DCAlom7LrMTP3hMhg/Hw94ukopTyEiPD41T157paBrD+UzbSFW8gtrmiT7+0R1fB4nnbKKKVc17SRXZh/TzIHThVy6+ub2uRkJ7cv7sYYjueU6jVllFIu7Zp+sbw1cxR5Jed489vW76Jx+zX3wrIqiiqqSIzU4q6Ucm3JSVGsfnQcceGtv1uc2xf3dPvGtYlRurWeUsr1tdUSstsvy9TuSp6gM3ellPo/bl/c0/PKAHRZRiml6nD74p5xtpT2gX6EBbv9CpNSSjmN2xf39LNlJESFIKKX+lVKqVpuX9wzzpaSGKlvpiqlVF1uXdyNMaTnlembqUopVY9DxV1EJojIQRFJFZEnG3j8XhHJFpEd9ttM50c9X17JOcoqq7UNUiml6mnyXUgR8QXmANdg2wz7OxFZbYzZV2/ocmPMo62QsVHpZ22dMjpzV0qp/+TIzH0kkGqMOWKMOQe8A0xq3ViOqb0+g87clVLqPzlS3OOB9DofZ9iP1TdFRHaJyAoRSWzoC4nILBFJEZGU7OzsFsT9Txk6c1dKqQY5Utwb6jGsv63Ih0CSMWYQ8DmwuKEvZIxZYIxJNsYkx8TENC9pA9LPlhIZ4k+7QO1xV0qpuhwp7hlA3Zl4ApBZd4AxJtcYU3uR4oXAcOfEayLY2TISo3TWrpRS9TlS3L8DeopINxEJAKYCq+sOEJG4Oh9OBPY7L2LjMvJsm3QopZT6T00Wd2NMFfAo8Am2ov0vY8xeEXlWRCbahz0mIntFZCfwGHBvawWuVVNjyMgv02vKKKVUAxxarDbGrAHW1Dv2dJ37TwFPOTfahWUXV3CuqkZn7kop1QC3PUP1ZL6tUyZei7tSSp3HbYv7qfxygDbZ0UQppdyN2xb3TPvMvXOEFnellKrPfYt7QRmhAb6EBWmPu1JK1ee+xT2/jM4RwXodd6WUaoDbFvdTBeXE6ZKMUko1yG2Le2Z+GfERQVbHUEopl+SWxb28spqc4nPaKaOUUo1wy+J+usDWBqmdMkop1TC3LO6ZBfY2yHBdllFKqYa4Z3HP15m7UkpdiFsW91P2E5g66cxdKaUa5JbFPbOgjOh2AQT5+1odRSmlXJJ7Fvf8cu2UUUqpC3DT4l5GZ+1xV0qpRrldcTfGkJlfpjN3pZS6AIeKu4hMEJGDIpIqIk828HigiCy3P75FRJKcHbRWYXkVJeeqiddOGaWUalSTxV1EfIE5wPVAP2CaiPSrN+x+4Kwx5hLgReB5ZwetVXup3zhdllFKqUY5MnMfCaQaY44YY84B7wCT6o2ZBCy2318BXCWtdLnGUwV6HXellGqKI8U9Hkiv83GG/ViDY+wbahcAHep/IRGZJSIpIpKSnZ3dosBhQf5c1z9WN8ZWSqkLcGSni4Zm4KYFYzDGLAAWACQnJ5/3uCOSk6JITopqyacqpZTXcGTmngEk1vk4AchsbIyI+AHhQJ4zAiqllGo+R4r7d0BPEekmIgHAVGB1vTGrgRn2+7cCXxpjWjQzV0opdfGaXJYxxlSJyKPAJ4AvsMgYs1dEngVSjDGrgTeBpSKSim3GPrU1QyullLowh3aXNsasAdbUO/Z0nfvlwG3OjaaUUqql3O4MVaWUUk3T4q6UUh5Ii7tSSnkgLe5KKeWBxKqORRHJBo638NOjgRwnxmlL7ppdc7ctzd223Cl3V2NMTFODLCvuF0NEUowxyVbnaAl3za6525bmblvumvtCdFlGKaU8kBZ3pZTyQO5a3BdYHeAiuGt2zd22NHfbctfcjXLLNXellFIX5q4zd6WUUhegxV0ppTyQ2xX3pjbrtpKIJIrIVyKyX0T2isjj9uO/F5GTIrLDfruhzuc8ZX8uB0XkOguzHxOR3fZ8KfZjUSLymYgctv8ZaT8uIvKKPfcuERlmUebedV7THSJSKCJPuOLrLSKLRCRLRPbUOdbs11dEZtjHHxaRGQ19rzbI/RcROWDPtkpEIuzHk0SkrM7r/nqdzxlu//lKtT+3VtmG04Hszf7ZcOWac0HGGLe5YbvkcBrQHQgAdgL9rM5VJ18cMMx+vz1wCNum4r8HftHA+H725xAIdLM/N1+Lsh8Dousd+zPwpP3+k8Dz9vs3AGux7cA1GtjiAq+9L3Aa6OqKrzcwHhgG7Gnp6wtEAUfsf0ba70dakPtawM9+//k6uZPqjqv3dbYCY+zPaS1wvUWvebN+Nly95lzo5m4zd0c267aMMeaUMWa7/X4RsJ/z95utaxLwjjGmwhhzFEjF9hxdRd2NzxcDk+scX2JsNgMRIhJnRcA6rgLSjDEXOuvZstfbGLOe83cna+7rex3wmTEmzxhzFvgMmNDWuY0xnxrbXskAm7HtztYoe/YwY8wmY6ukS/jhubaaRl7zxjT2s+HSNedC3K24O7JZt0sQkSRgKLDFfuhR+6+xi2p//ca1no8BPhWRbSIyy34s1hhzCmz/cQEd7cddKXetqcCyOh+7+usNzX99XS0/wH3YZuK1uonI9yLytYhcZj8Wjy1rLatzN+dnwxVfc4e4W3F3aCNuq4lIO+A94AljTCEwD+gBDAFOAX+rHdrAp1v1fMYZY4YB1wOPiMj4C4x1pdyIbfvHicC79kPu8HpfSGM5XSq/iPwGqALesh86BXQxxgwFfg68LSJhuFbu5v5suFL2ZnG34u7IZt2WEhF/bIX9LWPMSgBjzBljTLUxpgZYyA9LAS7zfIwxmfY/s4BV2DKeqV1usf+ZZR/uMrntrge2G2POgHu83nbNfX1dJr/9zdwbgbvsSy3YlzRy7fe3YVur7oUtd92lGyt/zpv7s+Eyr3lzuVtxd2SzbsvYOwDeBPYbY16oc7zuevTNQO2796uBqSISKCLdgJ7Y3nhqUyISKiLta+9je8NsD/+58fkM4AP7/dXAdHtXx2igoHZ5wSLTqLMk4+qvdx3NfX0/Aa4VkUj7csK19mNtSkQmAP8NTDTGlNY5HiMivvb73bG9vkfs2YtEZLT938h0fniubaoFPxsuXXMuyOp3dJt7w9ZJcAjbrOA3Vuepl+1SbL+y7QJ22G83AEuB3fbjq4G4Op/zG/tzOUgbdBA0krs7ti6AncDe2tcV6AB8ARy2/xllPy7AHHvu3UCyha95CJALhNc55nKvN7b/fE4Bldhmg/e35PXFtsadar/9xKLcqdjWoWt/xl+3j51i//nZCWwHbqrzdZKxFdI04DXsZ8dbkL3ZPxuuXHMudNPLDyillAdyt2UZpZRSDtDirpRSHkiLu1JKeSAt7kop5YG0uCullAfS4q6UUh5Ii7tSSnmg/w+JuUDmBYrc8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def inc_p(incentive):\n",
    "    eff=10*(1-np.exp(-incentive/400))\n",
    "    return 20*(1-np.exp(-eff/5))\n",
    "\n",
    "\n",
    "def total_rev(premiums,incentives):\n",
    "    return np.sum(np.multiply(inc_p(incentives)/100,premiums)-incentives)\n",
    "\n",
    "t=[total_rev(test_data.premium,np.ones((test_data.shape[0],))*r) for r in range(1651)]\n",
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 39582909.54636536)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(t),total_rev(test_data.premium,np.ones((test_data.shape[0],))*np.argmax(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def incentive_for_max_perm(prem):\n",
    "    return np.argmax([inc_p(i)*prem/100 - i for i in range(1651)])\n",
    "incentive_for_max_perm(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff5a464f2464461ac6b7a11a6e37a37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([183., 446., 446.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tqdm import tnrange\n",
    "# incentives=np.zeros((test_data.shape[0],))\n",
    "# for i in tnrange(incentives.shape[0]):\n",
    "#     incentives[i]=incentive_for_max_perm(test_data.iloc[i]['premium'])\n",
    "# incentives[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('incentive1',incentives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,renewal,incentives\n",
      "649,0.991133,183\n",
      "81136,0.981500,446\n",
      "70762,0.780981,446\n",
      "53935,0.975321,276\n",
      "15476,0.955694,399\n",
      "64797,0.983678,446\n",
      "67412,0.831585,183\n",
      "44241,0.821517,276\n",
      "5069,0.990382,487\n"
     ]
    }
   ],
   "source": [
    "best_clfs[0].fit(train_data.values,Y.values)\n",
    "best_clfs[1].fit(train_data.values,Y.values)\n",
    "results['renewal']=(best_clfs[0].predict_proba(test_data)[:,1]+best_clfs[1].predict_proba(test_data)[:,1])/2\n",
    "results['incentives']=incentives.astype('int')\n",
    "\n",
    "results.to_csv('submission/lgb_rf_div2.csv',index=False,float_format='%.6f')\n",
    "!head submission/lgb_rf_div2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,renewal,incentives\n",
      "649,0.99206,183\n",
      "81136,0.98488,446\n",
      "70762,0.79942,446\n",
      "53935,0.97486,276\n",
      "15476,0.96044,399\n",
      "64797,0.98645,446\n",
      "67412,0.83556,183\n",
      "44241,0.78625,276\n",
      "5069,0.99009,487\n"
     ]
    }
   ],
   "source": [
    "!head submission/lgb_tune.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,renewal,incentives\n",
      "649,0.993912,183\n",
      "81136,0.981488,446\n",
      "70762,0.745589,446\n",
      "53935,0.973516,276\n",
      "15476,0.964192,399\n",
      "64797,0.986993,446\n",
      "67412,0.824899,183\n",
      "44241,0.782331,276\n",
      "5069,0.993916,487\n"
     ]
    }
   ],
   "source": [
    "!head submission/lgb_deep_tuned.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
