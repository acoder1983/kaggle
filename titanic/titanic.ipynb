{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## background \n",
    "- 32% survival\n",
    "- women,children,upper class more likely survived\n",
    "- not enough boats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "passenger_train=pd.read_csv('train.csv')\n",
    "target_col='Survived'\n",
    "id_col='PassengerId'\n",
    "target=passenger_train[target_col]\n",
    "total_num=len(passenger_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe number features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train[['Pclass','Survived']].groupby('Pclass').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train[['Sex','Survived']].groupby('Sex').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# g = sns.FacetGrid(passenger_train, col='Survived')\n",
    "# g.map(plt.hist, 'Age', bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(passenger_train, col='Survived')\n",
    "# g.map(plt.hist, 'Pclass', bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop useless cols\n",
    "ticket has too many duplicates,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols=[id_col,target_col,'Ticket',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from util import *\n",
    "from label_binary import LabelBinarizerEx\n",
    "from df_pipeline import DfPipeline\n",
    "from binning import Binner\n",
    "from title import TitleExtractor\n",
    "from cabin import HasCabin\n",
    "from ensemble import EnsembleStackClassifierEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer,StandardScaler\n",
    "\n",
    "def featuring(df, num_cols=[], cat_cols=[], bin_cols=[]):\n",
    "    num_pipelines=[(c,Pipeline([\n",
    "        ('select',DataFrameSelecter([c])),\n",
    "        ('fill',Imputer(strategy='median')),\n",
    "#         ('scale',StandardScaler()),\n",
    "    ])) for c in num_cols]\n",
    "\n",
    "    cat_pipelines=[(c, Pipeline([\n",
    "        ('select',DataFrameSelecter([c])),\n",
    "        ('encode',LabelBinarizerEx([c])),\n",
    "    ])) if isinstance(c,str) else c for c in cat_cols ]\n",
    "    \n",
    "    bin_pipelines=[(c[0], Pipeline([\n",
    "        ('select',DataFrameSelecter([c[0]])),\n",
    "        ('fill',Imputer(strategy='median')),\n",
    "        ('bin',c[1]),\n",
    "    ])) for c in bin_cols ]\n",
    "\n",
    "    full_pipeline=DfPipeline(num_pipelines+cat_pipelines+bin_pipelines)\n",
    "\n",
    "    prepared_df=full_pipeline.fit_transform(df)\n",
    "\n",
    "    return prepared_df,full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with raw models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "def trainRawModels(train_data, target):\n",
    "    clfs=[#LogisticRegression(),SGDClassifier(), KNeighborsClassifier(), GaussianNB(),\n",
    "          LogisticRegression(),SVC(),RandomForestClassifier(),GradientBoostingClassifier(),\n",
    "        AdaBoostClassifier(), ExtraTreesClassifier(), XGBClassifier()]\n",
    "    scores=[cross_val_score(clf,train_data,target,scoring='accuracy',cv=10,n_jobs=-1).mean() for clf in clfs]\n",
    "\n",
    "    labels=[c.__class__.__name__[:3] for c in clfs]\n",
    "    X=np.arange(len(clfs))\n",
    "    bar(X,scores,tick_label=labels,color='rgb')\n",
    "    ylim(0.5,1.0)\n",
    "    show()\n",
    "    print(sorted(zip(labels,scores),key=lambda x:x[1],reverse=True)[:3])\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing ages according to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ages=passenger_train[passenger_train['Age'].isnull()]\n",
    "class_ages=passenger_train.groupby(['Pclass','Sex']).median()['Age']\n",
    "for i in missing_ages.index:\n",
    "    passenger_train.loc[i,'Age'] = class_ages[passenger_train.iloc[i]['Pclass'],passenger_train.iloc[i]['Sex']]\n",
    "passenger_train['Age'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just use num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=passenger_train.describe()\n",
    "num_cols=list(summary.columns)\n",
    "for c in drop_cols:\n",
    "    if c in num_cols:\n",
    "        num_cols.remove(c) \n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binarize category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=list(set(passenger_train.columns)-set(summary.columns))\n",
    "for c in ['Name','Ticket','Cabin']:\n",
    "    cat_cols.remove(c)\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discretize num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ages=passenger_train['Age'].quantile(np.linspace(0.1,1,7))\n",
    "# ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fares=passenger_train['Fare'].quantile(np.linspace(0.1,1,5))\n",
    "# fares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols=[('Age',Binner([14.,35.,50.])),\n",
    "          ('Fare',Binner([8.,14.,31.,66.])),\n",
    "         ]\n",
    "[num_cols.remove(c[0]) for c in bin_cols]\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract new features\n",
    "extract title from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train2=passenger_train.copy()\n",
    "# passenger_train2['Title'] = passenger_train2['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "# pd.crosstab(passenger_train2['Title'], passenger_train2['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=LabelBinarizerEx(['Title'])\n",
    "cat_cols.append(('Name',Pipeline([\n",
    "        ('select',DataFrameSelecter(['Name'])),\n",
    "        ('extract',TitleExtractor()),\n",
    "        ('encode',l),\n",
    "    ])))\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make new features\n",
    "sibsp+parch to make IsAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train2= passenger_train.copy()\n",
    "# passenger_train2['FamilySize']=passenger_train2['SibSp']+passenger_train2['Parch']+1\n",
    "# passenger_train2['IsAlone'] = (passenger_train2['FamilySize'] == 1).astype(int)\n",
    "# passenger_train2.groupby('IsAlone').mean()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train['FamilySize']=passenger_train['SibSp']+passenger_train['Parch']+1\n",
    "# passenger_train['IsAlone'] = (passenger_train['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# prepared_passenger_train = featuring(passenger_train,['Pclass','IsAlone'],['Sex','Embarked'],bin_cols)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add feature HasCabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.append(('Cabin',Pipeline([\n",
    "        ('select',DataFrameSelecter(['Cabin'])),\n",
    "        ('extract',HasCabin()),\n",
    "    ])))\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clfs=trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add feature class*age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train['Pclass*Age']=prepared_passenger_train['Pclass']*prepared_passenger_train['Age']\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train=prepared_passenger_train.drop(['Pclass','Age'],axis=1)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train.drop('Sex_female',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train_surv=prepared_passenger_train.copy()\n",
    "# prepared_passenger_train_surv['Survived']=target\n",
    "# prepared_passenger_train_surv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pg={'max_depth':[2,3,4,5,6],'learning_rate':[0.001,0.01,0.05,0.1,0.5],'n_estimators':[50,100,200,300,500]}\n",
    "# g=GridSearchCV(XGBClassifier(),param_grid=pg,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "# g.fit(prepared_passenger_train,target)\n",
    "# print(g.best_score_, g.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb=XGBClassifier(\n",
    "#     #learning_rate = 0.02,\n",
    "#  n_estimators= 2000,\n",
    "#  max_depth= 4,\n",
    "#  min_child_weight= 2,\n",
    "#  #gamma=1,\n",
    "#  gamma=0.9,                        \n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread= -1,\n",
    "#  scale_pos_weight=1)\n",
    "# scores=cross_val_score(xgb,prepared_passenger_train,target,cv=10,n_jobs=-1,scoring='accuracy')\n",
    "# scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs=[#LogisticRegression(),SGDClassifier(), KNeighborsClassifier(), GaussianNB(),\n",
    "          LogisticRegression(),SVC(probability=True),RandomForestClassifier(),#GradientBoostingClassifier(),\n",
    "#        AdaBoostClassifier(), ExtraTreesClassifier(), XGBClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brew.base import Ensemble\n",
    "from brew.stacking import EnsembleStackClassifier,EnsembleStack\n",
    "import sklearn\n",
    "\n",
    "layer_1 = Ensemble(clfs)\n",
    "layer_2 = Ensemble([sklearn.clone(clfs[0])])\n",
    "\n",
    "stack = EnsembleStack(cv=len(clfs))\n",
    "\n",
    "stack.add_layer(layer_1)\n",
    "stack.add_layer(layer_2)\n",
    "\n",
    "sclf = EnsembleStackClassifierEx(stack)\n",
    "scores=cross_val_score(sclf,prepared_passenger_train.values,target,cv=5,n_jobs=-1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_test=pd.read_csv('test.csv')\n",
    "# test_id=passenger_test[id_col]\n",
    "# drop_cols.remove(target_col)\n",
    "# passenger_test.drop(drop_cols,axis=1,inplace=True)\n",
    "# prepared_passenger_test=full_pl.transform(passenger_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
