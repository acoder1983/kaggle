{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## background \n",
    "- 32% survival\n",
    "- women,children,upper class more likely survived\n",
    "- not enough boats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from util import *\n",
    "from onehot import LabelBinarizerEx\n",
    "from pipeline import FeaturePipeline, DataFramePipeline\n",
    "from binning import Binner\n",
    "from title import TitleExtractor\n",
    "from cabin import HasCabin\n",
    "from ensemble import EnsembleStackClassifierEx\n",
    "from addcols import AddColumns\n",
    "from impute import GroupImputer\n",
    "from alone import IsAlone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "passenger_train=pd.read_csv('train.csv')\n",
    "target_col='Survived'\n",
    "id_col='PassengerId'\n",
    "target=passenger_train[target_col]\n",
    "total_num=len(passenger_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers=passenger_train.copy()\n",
    "passengers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe number features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers[['Pclass','Survived']].groupby('Pclass').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class 1 has more survivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers[['Sex','Survived']].groupby('Sex').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "female survived more than male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers[['SibSp','Survived']].groupby('SibSp').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems with one or two sps has more survivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers[['Parch','Survived']].groupby('Parch').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train[['Embarked','Survived']].groupby('Embarked').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers['FamilySize']=passengers['SibSp']+passengers['Parch']\n",
    "passengers[['FamilySize','Survived']].groupby('FamilySize').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Binner(strategy=[4])\n",
    "passengers['BigFamily']=b.transform(passengers[['FamilySize']].values)\n",
    "passengers[['BigFamily','Survived']].groupby('BigFamily').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Binner(strategy=[1])\n",
    "passengers['IsAlone']=1-b.transform(passengers[['FamilySize']].values)\n",
    "passengers[['IsAlone','Survived']].groupby('IsAlone').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binning age and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=Binner([14.,35.,50.])\n",
    "passengers['Age']=b.transform(passengers[['Age']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers[['Age','Survived']].groupby('Age').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Binner([8.,14.,31.,66.])\n",
    "passengers['Fare']=b.transform(passengers[['Fare']].values)\n",
    "passengers[['Fare','Survived']].groupby('Fare').mean().sort_values('Survived',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# g = sns.FacetGrid(passenger_train, col='Survived')\n",
    "# g.map(plt.hist, 'Age', bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(passenger_train, col='Survived')\n",
    "# g.map(plt.hist, 'Pclass', bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop useless cols\n",
    "ticket has too many duplicates,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols=[id_col,target_col,'Ticket',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline=DataFramePipeline([\n",
    "    FeaturePipeline('Name','Title',Pipeline([('title',TitleExtractor())])),\n",
    "    FeaturePipeline('Title','',Pipeline([('onehot',LabelBinarizerEx(['Title']))])),\n",
    "    FeaturePipeline('Sex','',Pipeline([('onehot',LabelBinarizerEx(['Sex']))])),\n",
    "    FeaturePipeline(['Pclass','Sex','Age'],'Age_band',Pipeline([('impute',GroupImputer(['Pclass','Sex','Age'])),\n",
    "                                                                ('binning',Binner([14.,35.,50.]))\n",
    "                                              ])),\n",
    "    FeaturePipeline(['SibSp','Parch'],'FamilySize',Pipeline([('addcols',AddColumns())])),\n",
    "    FeaturePipeline('FamilySize','IsAlone',Pipeline([('alone',IsAlone())])),\n",
    "    FeaturePipeline('Fare','Fare_band',Pipeline([('binning',Binner([8.,14.,31.,66.]))])),\n",
    "    FeaturePipeline('Cabin','Cabin_has',Pipeline([('has',HasCabin())])),\n",
    "    FeaturePipeline('Embarked','',Pipeline([('onehot',LabelBinarizerEx(['Embarked']))])),\n",
    "])\n",
    "\n",
    "prepared_passenger_train=full_pipeline.fit_transform(passenger_train)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_passenger_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer,StandardScaler\n",
    "\n",
    "def featuring(df, num_cols=[], cat_cols=[], bin_cols=[]):\n",
    "    num_pipelines=[(c,Pipeline([\n",
    "        ('select',DataFrameSelecter([c])),\n",
    "        ('fill',Imputer(strategy='median')),\n",
    "#         ('scale',StandardScaler()),\n",
    "    ])) for c in num_cols]\n",
    "\n",
    "    cat_pipelines=[(c, Pipeline([\n",
    "        ('select',DataFrameSelecter([c])),\n",
    "        ('encode',LabelBinarizerEx([c])),\n",
    "    ])) if isinstance(c,str) else c for c in cat_cols ]\n",
    "    \n",
    "    bin_pipelines=[(c[0], Pipeline([\n",
    "        ('select',DataFrameSelecter([c[0]])),\n",
    "        ('fill',Imputer(strategy='median')),\n",
    "        ('bin',c[1]),\n",
    "    ])) for c in bin_cols ]\n",
    "\n",
    "    full_pipeline=DfPipeline(num_pipelines+cat_pipelines+bin_pipelines)\n",
    "\n",
    "    prepared_df=full_pipeline.fit_transform(df)\n",
    "\n",
    "    return prepared_df,full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "def trainRawModels(train_data, target):\n",
    "    clfs=[LogisticRegression(n_jobs=-1),\n",
    "          SVC(probability=True),\n",
    "          RandomForestClassifier(n_jobs=-1),\n",
    "          GradientBoostingClassifier(),\n",
    "          AdaBoostClassifier(), \n",
    "          ExtraTreesClassifier(n_jobs=-1), \n",
    "          XGBClassifier()]\n",
    "    scores=[cross_val_score(clf,train_data,target,scoring='accuracy',cv=10,n_jobs=-1).mean() for clf in clfs]\n",
    "\n",
    "    labels=[c.__class__.__name__[:3] for c in clfs]\n",
    "    X=np.arange(len(clfs))\n",
    "    bar(X,scores,tick_label=labels,color='rgb')\n",
    "    ylim(0.5,1.0)\n",
    "    show()\n",
    "    print(sorted(zip(labels,scores),key=lambda x:x[1],reverse=True))\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing ages according to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_index=passenger_train[passenger_train['Age'].isnull()].index\n",
    "\n",
    "class_ages=passenger_train.groupby(['Pclass','Sex']).median()['Age']\n",
    "class_ages\n",
    "# passenger_train.loc[missing_index,'Age']\n",
    "# class_ages[tuple([passenger_train.loc[5,'Pclass'],passenger_train.loc[5,'Sex']])]\n",
    "# for i in missing_ages.index:\n",
    "#     passenger_train.loc[i,'Age'] = class_ages[passenger_train.iloc[i]['Pclass'],passenger_train.iloc[i]['Sex']]\n",
    "# passenger_train['Age'].count()\n",
    "# help(class_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(class_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ages[1,'male']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binarize category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=list(set(passenger_train.columns)-set(summary.columns))\n",
    "for c in ['Name','Ticket','Cabin']:\n",
    "    cat_cols.remove(c)\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discretize num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ages=passenger_train['Age'].quantile(np.linspace(0.1,1,7))\n",
    "# ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fares=passenger_train['Fare'].quantile(np.linspace(0.1,1,5))\n",
    "# fares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_cols=[('Age',Binner([14.,35.,50.])),\n",
    "          ('Fare',Binner([8.,14.,31.,66.])),\n",
    "         ]\n",
    "[num_cols.remove(c[0]) for c in bin_cols]\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract new features\n",
    "extract title from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train2=passenger_train.copy()\n",
    "# passenger_train2['Title'] = passenger_train2['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "# pd.crosstab(passenger_train2['Title'], passenger_train2['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=LabelBinarizerEx(['Title'])\n",
    "cat_cols.append(('Name',Pipeline([\n",
    "        ('select',DataFrameSelecter(['Name'])),\n",
    "        ('extract',TitleExtractor()),\n",
    "        ('encode',l),\n",
    "    ])))\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make new features\n",
    "sibsp+parch to make IsAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train2= passenger_train.copy()\n",
    "# passenger_train2['FamilySize']=passenger_train2['SibSp']+passenger_train2['Parch']+1\n",
    "# passenger_train2['IsAlone'] = (passenger_train2['FamilySize'] == 1).astype(int)\n",
    "# passenger_train2.groupby('IsAlone').mean()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train['FamilySize']=passenger_train['SibSp']+passenger_train['Parch']+1\n",
    "# passenger_train['IsAlone'] = (passenger_train['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# prepared_passenger_train = featuring(passenger_train,['Pclass','IsAlone'],['Sex','Embarked'],bin_cols)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add feature HasCabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols.append(('Cabin',Pipeline([\n",
    "        ('select',DataFrameSelecter(['Cabin'])),\n",
    "        ('extract',HasCabin()),\n",
    "    ])))\n",
    "\n",
    "prepared_passenger_train,full_pipeline = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clfs=trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add feature class*age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train['Pclass*Age']=prepared_passenger_train['Pclass']*prepared_passenger_train['Age']\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train=prepared_passenger_train.drop(['Pclass','Age'],axis=1)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train = featuring(passenger_train,num_cols,cat_cols,bin_cols)\n",
    "# prepared_passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train.drop('Sex_female',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainRawModels(prepared_passenger_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_train_surv=prepared_passenger_train.copy()\n",
    "# prepared_passenger_train_surv['Survived']=target\n",
    "# prepared_passenger_train_surv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pg={'max_depth':[2,3,4,5,6],'learning_rate':[0.001,0.01,0.05,0.1,0.5],'n_estimators':[50,100,200,300,500]}\n",
    "# g=GridSearchCV(XGBClassifier(),param_grid=pg,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "# g.fit(prepared_passenger_train,target)\n",
    "# print(g.best_score_, g.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb=XGBClassifier(\n",
    "#     #learning_rate = 0.02,\n",
    "#  n_estimators= 2000,\n",
    "#  max_depth= 4,\n",
    "#  min_child_weight= 2,\n",
    "#  #gamma=1,\n",
    "#  gamma=0.9,                        \n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread= -1,\n",
    "#  scale_pos_weight=1)\n",
    "# scores=cross_val_score(xgb,prepared_passenger_train,target,cv=10,n_jobs=-1,scoring='accuracy')\n",
    "# scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs=[\n",
    "#       LogisticRegression(n_jobs=-1),\n",
    "      SVC(probability=True),\n",
    "#       RandomForestClassifier(n_jobs=-1),\n",
    "#       GradientBoostingClassifier(),\n",
    "#       AdaBoostClassifier(), \n",
    "#       ExtraTreesClassifier(n_jobs=-1), \n",
    "#       XGBClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_set=[\n",
    "#      {'C':[0.01,0.1,0.5,1.]},\n",
    "                {'C':[0.01,0.1,0.5,1.],'kernel':['rbf','poly','sigmoid'],'gamma':[0.01,0.1,0.5],'degree':[2,3,4],'coef0':[0.01,0.1,1.,10.]},\n",
    "#                 {'n_estimators':[50,100,200,300],'max_depth':[5,10,15]},\n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,200,300],'max_depth':[3,5,8]},\n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,200,300]},\n",
    "#                 {'n_estimators':[50,100,200,300],'max_depth':[5,10,15]},\n",
    "#                 {'learning_rate':[0.01,0.1,1.0],'n_estimators':[100,200,300],'max_depth':[5,10,15],'gamma':[0.01,0.1,0.5]},\n",
    "               ]\n",
    "\n",
    "gs=[]\n",
    "results=[]\n",
    "# for i in range(len(clfs)):\n",
    "#     gs.append(GridSearchCV(estimator=clfs[i],param_grid=param_grid_set[i],scoring='accuracy',n_jobs=-1,verbose=1))\n",
    "#     gs[i].fit(prepared_passenger_train,target)\n",
    "#     results.append((gs[i].best_estimator_,gs[i].best_score_))\n",
    "sorted(results,key=lambda x:x[1],reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs=[g.best_estimator_ for g in gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# help(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emsembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# voter=VotingClassifier(estimators=[(c.__class__.__name__, c) for c in clfs], voting='soft',n_jobs=-1)\n",
    "# scores=cross_val_score(voter,prepared_passenger_train,target,cv=10,n_jobs=-1,scoring='accuracy')\n",
    "# scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from brew.base import Ensemble\n",
    "# from brew.stacking import EnsembleStackClassifier,EnsembleStack\n",
    "# import sklearn\n",
    "\n",
    "# layer_1 = Ensemble(clfs)\n",
    "# layer_2 = Ensemble([sklearn.clone(clfs[0])])\n",
    "\n",
    "# stack = EnsembleStack(cv=len(clfs))\n",
    "\n",
    "# stack.add_layer(layer_1)\n",
    "# stack.add_layer(layer_2)\n",
    "\n",
    "# sclf = EnsembleStackClassifierEx(stack)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # X_train,y_train,X_test,y_test=train_test_split(prepared_passenger_train.values,target,test_size=0.3,random_state=0)\n",
    "# # print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "# sclf.fit(prepared_passenger_train.values[:600],target[:600])\n",
    "# sclf.score(prepared_passenger_train.values[600:],target[600:])\n",
    "# scores=cross_val_score(sclf,prepared_passenger_train.values,target,cv=5,n_jobs=-1)\n",
    "# scores.mean()\n",
    "\n",
    "# sclf.fit(prepared_passenger_train.values[:600],target[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passenger_test=pd.read_csv('test.csv')\n",
    "# test_id=passenger_test[id_col]\n",
    "# cols=drop_cols.copy()\n",
    "# cols.remove(target_col)\n",
    "# passenger_test.drop(cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared_passenger_test=full_pipeline.transform(passenger_test)\n",
    "# prepared_passenger_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf=gs[0].best_estimator_\n",
    "# # clf.fit(prepared_passenger_train,target)\n",
    "# survived=clf.predict(prepared_passenger_test.values)\n",
    "# test_Survived = pd.Series(survived, name=\"Survived\")\n",
    "# results = pd.concat([test_id,test_Survived],axis=1)\n",
    "# results.to_csv(\"result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# help(AdaBoostClassifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
