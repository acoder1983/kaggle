{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## background \n",
    "- 32% survival\n",
    "- women,children,upper class more likely survived\n",
    "- not enough boats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Imputer\n",
    "from util import *\n",
    "from onehot import LabelBinarizerEx\n",
    "from pipeline import FeaturePipeline, DataFramePipeline\n",
    "from binning import Binner\n",
    "from title import TitleExtractor\n",
    "from cabin import HasCabin\n",
    "from ensemble import EnsembleStackClassifierEx\n",
    "from addcols import AddColumns\n",
    "from impute import GroupImputer,MixImputer\n",
    "from alone import IsAlone\n",
    "from scipy.stats import boxcox\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger_train=pd.read_csv('raw_data/train.csv')\n",
    "passenger_test=pd.read_csv('raw_data/test.csv')\n",
    "target_col='Survived'\n",
    "id_col='PassengerId'\n",
    "target=passenger_train[target_col]\n",
    "total_num=len(passenger_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_test.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df=pd.concat([passenger_train.drop(target_col,axis=1),passenger_test]).drop(id_col,axis=1)\n",
    "raw_df.index=np.arange(len(raw_df))\n",
    "org_cols=raw_df.columns\n",
    "\n",
    "age_group=raw_df.groupby(['Pclass','Sex']).mean()['Age']\n",
    "missing_index=raw_df[raw_df.Age.isnull()].index\n",
    "for i in missing_index:\n",
    "    raw_df.loc[i,'Age'] = age_group[(raw_df.loc[i,'Pclass'],raw_df.loc[i,'Sex'])]\n",
    "    \n",
    "raw_df.Fare=Imputer(strategy='mean').fit_transform(raw_df.Fare.values.reshape(-1,1))\n",
    "\n",
    "raw_df['FamilySize']=raw_df.SibSp+raw_df.Parch\n",
    "\n",
    "raw_df['IsAlone']=(raw_df.FamilySize==0).astype('int')\n",
    "\n",
    "for c in ['Pclass','Age','Fare','SibSp','Parch','FamilySize']:\n",
    "    new_c=c+'_Norm'\n",
    "    raw_df[new_c]=raw_df[c]\n",
    "    if raw_df[new_c].min()<=0.:\n",
    "        raw_df[new_c]=raw_df[new_c]+abs(raw_df[new_c].min())+0.1\n",
    "    tranformed,_=boxcox(raw_df[new_c])\n",
    "    raw_df[new_c]=StandardScaler().fit_transform(tranformed.reshape(-1,1))\n",
    "import re\n",
    "\n",
    "# def extractTitle(name):\n",
    "#     m = re.search(' \\w+\\\\.',name)\n",
    "#     if m:\n",
    "#         return m.group()[1:-1]\n",
    "#     else:\n",
    "#         return np.nan\n",
    "    \n",
    "def extractTitle(name):\n",
    "    title=np.nan\n",
    "    m = re.search(' \\w+\\\\.',name)\n",
    "    if m:\n",
    "        t=m.group()[1:-1]\n",
    "        if t in ['Mr','Miss','Mrs','Master']:\n",
    "            title = t\n",
    "    return title\n",
    "    \n",
    "raw_df['Title']=raw_df.Name.apply(extractTitle)\n",
    "\n",
    "# def extractTicketNumber(ticket):\n",
    "#     try:\n",
    "#         return float(ticket)\n",
    "#     except:\n",
    "#         splits=ticket.split()\n",
    "#         if len(splits)>1:\n",
    "#             return float(splits[1])\n",
    "#         else:\n",
    "#             return np.nan\n",
    "        \n",
    "# raw_df['Ticket_Number']=raw_df.Ticket.apply(extractTicketNumber)\n",
    "\n",
    "# def extractTicketLocation(ticket):\n",
    "#     m = re.search('\\w+ ',ticket)\n",
    "#     if m:\n",
    "#         return m.group()[0]\n",
    "#     else:\n",
    "#         return np.nan\n",
    "\n",
    "# raw_df['Ticket_Location']=raw_df.Ticket.apply(extractTicketLocation)\n",
    "\n",
    "raw_df['HasCabin']=(raw_df.Cabin.isnull()==False).astype('int')\n",
    "\n",
    "raw_df['Embarked_Imp']=MixImputer().fit_transform(raw_df[['Embarked']])\n",
    "\n",
    "raw_df=pd.get_dummies(raw_df,columns=['Sex','Title','Embarked_Imp'])\n",
    "\n",
    "pre_df=raw_df.drop(list(set(org_cols)-set(['Sex','Title']))+['FamilySize'],axis=1)\n",
    "pre_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pre_df[:len(passenger_train)]\n",
    "test_data=pre_df[len(passenger_train):]\n",
    "len(train_data)==len(passenger_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hill_result={}\n",
    "from imp import reload\n",
    "from aml import auto_model_machine as aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME='warm-hill-lr-rf-gbt-svc-knn-cv5-drop'\n",
    "logger,handlers=initLogging(TASK_NAME)\n",
    "\n",
    "aml=reload(aml)\n",
    "bc=aml.BinaryClassifier.hillclimbing(train_data,target,('lr','rf','gbt','svc','knn'),hill_result,logger=logger,cv=5)\n",
    "resetLogging(logger,handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resetLogging(logger,handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier,LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "base_clfs=[\n",
    "#     bc,\n",
    "#     bc.get_nth_model(0),\n",
    "#     GradientBoostingClassifier(learning_rate=0.01,max_depth=5,max_features=None, n_estimators=100)\n",
    "      LogisticRegression(random_state=42),\n",
    "      SVC(probability=True,random_state=42),\n",
    "      RandomForestClassifier(random_state=42),\n",
    "      GradientBoostingClassifier(random_state=42),\n",
    "      AdaBoostClassifier(), \n",
    "      ExtraTreesClassifier(n_jobs=-1), \n",
    "#       XGBClassifier(),\n",
    "]\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "def trainModels(train_data, target):\n",
    "    scores=[cross_val_score(clf,train_data,target,scoring='accuracy',cv=5).mean() for clf in base_clfs]\n",
    "\n",
    "    labels=[c.__class__.__name__[:3] for c in base_clfs]\n",
    "    X=np.arange(len(base_clfs))\n",
    "    bar(X,scores,tick_label=labels,color='rgb')\n",
    "    show()\n",
    "    print(sorted(zip(labels,scores),key=lambda x:x[1],reverse=True))\n",
    "    \n",
    "trainModels(train_data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME='gbt-default-lesstitle-500'\n",
    "# clf=GradientBoostingClassifier(learning_rate=0.01,max_depth=5,)\n",
    "# clf.fit(train_data,target)\n",
    "# bc.select(12)\n",
    "# clf=bc\n",
    "# clf=GradientBoostingClassifier(learning_rate=0.1,max_depth=3,max_features=None,n_estimators=500,subsample=0.8)\n",
    "clf=GradientBoostingClassifier(n_estimators=500)\n",
    "clf.fit(train_data,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bc.fit_one(2,train_data.values,target)\n",
    "test_id=passenger_test[id_col]\n",
    "# clf=base_clfs[0]\n",
    "survived=clf.predict(test_data)\n",
    "test_Survived = pd.Series(survived, name=\"Survived\").astype(int)\n",
    "results = pd.concat([test_id,test_Survived],axis=1)\n",
    "results.to_csv(\"output/%s.csv\"%TASK_NAME,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
